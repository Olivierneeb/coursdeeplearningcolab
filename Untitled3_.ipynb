{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOQ+LPxS/cgGb11J1ZIS3nk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/Untitled3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWdcxZdBXNp7",
        "colab_type": "text"
      },
      "source": [
        "#Formation deep learning\n",
        "\n",
        "L'objet de ce TP est de présenter brievement les outils de deep learning Pytorch. Il comporte 3 parties\n",
        "\n",
        "1.   Les briques de bases\n",
        "2.   Le traitement d'ECG par convolution\n",
        "3.   Les réseaux récurrents\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVtpJwPzbtSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.autograd\n",
        "import torch.autograd.variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWiZxWIaZvjd",
        "colab_type": "text"
      },
      "source": [
        "##Les briques de bases\n",
        "\n",
        "La brique de base de pytorch est l'objet Variable : il stocke en interne les opérations effectués sur un tenseur, de sorte à pouvoir calculer **automatiquement** le gradient d'une valeur par rapport aux autres.\n",
        "Considérons le problème de moindre carré où on veut minimiser f(beta) = beta * beta + (Y-X * beta)*(Y-X * beta) : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHyz0wNpXNE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y,X,beta = torch.rand(11),torch.rand((11,3)),torch.autograd.Variable(torch.rand(3),requires_grad=True)\n",
        "loss = torch.sum((Y-torch.mv(X,beta))*(Y-torch.mv(X,beta)))+torch.sum(beta*beta)\n",
        "print(X,Y,beta)\n",
        "print(\"initial loss=\",loss)\n",
        "loss.backward()\n",
        "print(beta.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvIVYOkTeDj7",
        "colab_type": "text"
      },
      "source": [
        "Ci dessus le gradient est automatiquement calculé, permettant par exemple de faire une descente de gradient à la main simplement. Cela dit, des optimiseurs (typiquement la descente de gradient) sont déjà précodés : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoTpV9ZkeWFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "2c543a0b-867b-419b-d4cc-1c72200d05c5"
      },
      "source": [
        "optimizer = optim.SGD([beta], lr=0.00001, momentum=0)\n",
        "for i in range(10):\n",
        "  loss = torch.sum((Y-torch.mv(X,beta))*(Y-torch.mv(X,beta)))+torch.sum(beta*beta)\n",
        "  print(loss,beta)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print(\"final loss=\", torch.sum((Y-torch.mv(X,beta))*(Y-torch.mv(X,beta)))+torch.sum(beta*beta))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.8818, grad_fn=<AddBackward0>) tensor([0.4337, 0.4171, 0.5585], requires_grad=True)\n",
            "tensor(2.8807, grad_fn=<AddBackward0>) tensor([0.4336, 0.4170, 0.5584], requires_grad=True)\n",
            "tensor(2.8795, grad_fn=<AddBackward0>) tensor([0.4336, 0.4170, 0.5584], requires_grad=True)\n",
            "tensor(2.8784, grad_fn=<AddBackward0>) tensor([0.4335, 0.4169, 0.5583], requires_grad=True)\n",
            "tensor(2.8773, grad_fn=<AddBackward0>) tensor([0.4335, 0.4169, 0.5582], requires_grad=True)\n",
            "tensor(2.8761, grad_fn=<AddBackward0>) tensor([0.4334, 0.4168, 0.5582], requires_grad=True)\n",
            "tensor(2.8750, grad_fn=<AddBackward0>) tensor([0.4334, 0.4167, 0.5581], requires_grad=True)\n",
            "tensor(2.8739, grad_fn=<AddBackward0>) tensor([0.4334, 0.4167, 0.5580], requires_grad=True)\n",
            "tensor(2.8727, grad_fn=<AddBackward0>) tensor([0.4333, 0.4166, 0.5580], requires_grad=True)\n",
            "tensor(2.8716, grad_fn=<AddBackward0>) tensor([0.4333, 0.4165, 0.5579], requires_grad=True)\n",
            "final loss= tensor(2.8705, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KgDj0I6fio1",
        "colab_type": "text"
      },
      "source": [
        "Faire une descente de gradient sur ce problème simple est donc trivial... \n",
        "\n",
        "**Mais on n'est pas là pour faire de la régression moindre carré...**\n",
        "\n",
        "##Traitement de données ECG\n",
        "\n",
        "On considère maintenant des données (réelles - voir https://physionet.org/physiobank/database/qtdb/) d'ECG annotées - à chaque instant, on a 2 valeurs brutes (ne me demander pas à quoi ça correspond, je n'en ai aucune idée) **et** on sait si on est dans l'état P, T ou U (ne me demander pas à quoi ça correspond, je n'en ai aucune idée). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwlwHBha3I2y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "864fb44d-8605-4f19-fdd0-eff08fce0e6f"
      },
      "source": [
        "!wget \"https://github.com/achanhon/coursdeeplearningcolab/blob/master/ECG_data/alldata.npz?raw=true\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-31 13:58:30--  https://github.com/achanhon/coursdeeplearningcolab/blob/master/ECG_data/alldata.npz?raw=true\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/achanhon/coursdeeplearningcolab/raw/master/ECG_data/alldata.npz [following]\n",
            "--2020-01-31 13:58:30--  https://github.com/achanhon/coursdeeplearningcolab/raw/master/ECG_data/alldata.npz\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/achanhon/coursdeeplearningcolab/master/ECG_data/alldata.npz [following]\n",
            "--2020-01-31 13:58:30--  https://raw.githubusercontent.com/achanhon/coursdeeplearningcolab/master/ECG_data/alldata.npz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2009378 (1.9M) [application/octet-stream]\n",
            "Saving to: ‘alldata.npz?raw=true’\n",
            "\n",
            "alldata.npz?raw=tru 100%[===================>]   1.92M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-01-31 13:58:31 (38.3 MB/s) - ‘alldata.npz?raw=true’ saved [2009378/2009378]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFLTi2BThM4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "e52c2dc2-c50d-4920-9de1-b374c5f65090"
      },
      "source": [
        "import numpy as np\n",
        "allecgdata = np.load(\"alldata.npz?raw=true\")\n",
        "allecgdata = allecgdata[\"arr_0\"]\n",
        "print(allecgdata,allecgdata.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 4.75   4.77   4.78  ...  4.77   4.765  4.765]\n",
            "  [ 4.865  4.86   4.86  ...  4.915  4.915  4.91 ]\n",
            "  [ 0.     0.     0.    ...  1.     1.     1.   ]]\n",
            "\n",
            " [[ 4.75   4.725  4.725 ...  4.995  5.005  4.995]\n",
            "  [ 5.     5.01   5.025 ...  5.265  5.255  5.225]\n",
            "  [ 1.     1.     1.    ...  2.     2.     2.   ]]\n",
            "\n",
            " [[ 4.93   4.93   4.93  ...  6.58   6.975  7.025]\n",
            "  [ 5.115  5.12   5.105 ...  5.98   6.345  6.52 ]\n",
            "  [ 0.     0.     0.    ...  1.     1.     1.   ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-6.2   -6.2   -6.2   ... -6.34  -6.34  -6.34 ]\n",
            "  [-1.67  -1.675 -1.665 ... -1.67  -1.705 -1.73 ]\n",
            "  [ 0.     0.     0.    ...  1.     1.     1.   ]]\n",
            "\n",
            " [[-3.55  -3.545 -3.55  ... -3.635 -3.635 -3.635]\n",
            "  [-0.1   -0.1   -0.105 ... -0.11  -0.105 -0.115]\n",
            "  [ 0.     0.     0.    ...  2.     2.     2.   ]]\n",
            "\n",
            " [[-3.64  -3.64  -3.64  ... -3.715 -3.72  -3.755]\n",
            "  [-2.24  -2.23  -2.25  ... -2.115 -2.085 -2.045]\n",
            "  [ 0.     0.     0.    ...  1.     1.     1.   ]]] (105, 3, 8192)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYdb1Bv5hb8k",
        "colab_type": "text"
      },
      "source": [
        "Nous avons donc 105 enregistrements (1 par patients) de 8192 instants (je ne connais pas la fréquence). On va commencer par se familiariser avec les données : **70% du temps de développement c'est de s'adapter au données**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4XyWyYSh4yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython.display\n",
        "import PIL.Image\n",
        "\n",
        "def visualizecurve(x,y,z):\n",
        "    grid = np.ones((200,1000,3),dtype=int)*255\n",
        "    x = x[0:1000]\n",
        "    x = x-min(x)\n",
        "    x = x*400/max(x)\n",
        "    \n",
        "    x = np.minimum(x,np.ones(1000)*180)\n",
        "    x = x.astype(int)\n",
        "    y = y.astype(int)\n",
        "    \n",
        "    if z is not None:\n",
        "        for t in range(1000):\n",
        "            grid[x[t]][t][:] = 0\n",
        "            grid[0:20,t,y[t]] = 0            \n",
        "            grid[180:200,t,z[t]] = 0\n",
        "    else:\n",
        "        for t in range(1000):\n",
        "            grid[x[t]][t][:] = 0\n",
        "            grid[0:20,t,y[t]] = 0            \n",
        "        \n",
        "    return np.uint8(grid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2v5W4aiv03",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "bfe85576-1328-4f12-9084-d95c7702fde8"
      },
      "source": [
        "randompatient = np.random.randint(105, size=1)[0]\n",
        "IPython.display.display(PIL.Image.fromarray(visualizecurve(allecgdata[randompatient][1],allecgdata[randompatient][2],None)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAADICAIAAAD0hVwYAAANIUlEQVR4nO3d4W6zuBIAULja939l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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=1000x200 at 0x7F8B4600DC88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG_0hNG0jqgK",
        "colab_type": "text"
      },
      "source": [
        "On voit donc l'ECG et les 3 labels représentés par 3 couleurs au dessus.\n",
        "*Bon j'admets que c'est pas très beau comme affichage mais...*\n",
        "\n",
        "**Notre objectif est d'apprendre à un réseau à prédire ce label (à chaque instant) à partir de l'ECG. Lors de l'apprentissage le réseau utilise l'ECG et le label pour mettre à jours ses poids. En test, on n'utilise que l'ECG et on prédit un label (puis on compare avec le label réel pour voir si ça marche).**\n",
        "\n",
        "Commençons par couper train/test aléatoirement :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQdcGYfkgI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X,Y = [],[]    \n",
        "for i in range(allecgdata.shape[0]):\n",
        "    X.append(allecgdata[i][0:2])\n",
        "    Y.append(allecgdata[i][2].astype(int))\n",
        "\n",
        "X,Y = shuffle(X,Y)\n",
        "\n",
        "Xtest,Ytest = X[0:15],Y[0:15]\n",
        "X,Y = X[15:],Y[15:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAan3YmgmYuM",
        "colab_type": "text"
      },
      "source": [
        "Et introduisons notre fonction d'évaluation : on prend X, Y et un model et on compte le nombre de fois qu'on a prédit la bonne réponse - **accuracy** en anglais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vfAJbqWmdAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_model(X,Y,model):\n",
        "    cm = np.zeros((3,3),dtype=int)\n",
        "    Z = model(torch.Tensor(np.stack(X)))\n",
        "    Z = Z.cpu().data.numpy()\n",
        "    Z = np.argmax(Z,axis=1)\n",
        "    for i in range(len(Y)):\n",
        "        cm += confusion_matrix(Y[i], Z[i],list(range(3)))\n",
        "    return (cm[0][0]+cm[1][1]+cm[2][2])/(np.sum(cm)+1),cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIBUGaImjqXj",
        "colab_type": "text"
      },
      "source": [
        "Maintenant, définissons un réseau qui apprend à segmenter. Pour commencer on va mettre juste 2 couches avec 1 couche de pré traitement et une couche de pooling (ça va pas marcher mais c'est pour introduire le code)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rNSbJKklXh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PetitNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PetitNet, self).__init__()\n",
        "        self.bnm1 = nn.BatchNorm1d(2, momentum=0.1)\n",
        "        self.fc0 = nn.Conv1d(2, 32, kernel_size=11, padding=5)\n",
        "        self.fc11 = nn.Conv1d(32, 32, kernel_size=11, padding=5)\n",
        "        self.fc12 = nn.Conv1d(32, 32, kernel_size=11, padding=5)\n",
        "        self.fc13 = nn.Conv1d(32, 32, kernel_size=11, padding=5)\n",
        "        self.fc14 = nn.Conv1d(32, 32, kernel_size=11, padding=5)\n",
        "        self.fc15 = nn.Conv1d(32, 32, kernel_size=11, padding=5)\n",
        "        self.fc16 = nn.Conv1d(32, 32, kernel_size=11, padding=5)\n",
        "        self.fc17 = nn.Conv1d(32, 32, kernel_size=11, padding=5)\n",
        "        self.fc18 = nn.Conv1d(32, 32, kernel_size=11, padding=5)\n",
        "        self.fc19 = nn.Conv1d(32, 32, kernel_size=11, padding=5)\n",
        "        self.fc1 = nn.Conv1d(32, 3, kernel_size=11, padding=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = F.leaky_relu(self.fc0(x))\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "        x = F.leaky_relu(self.fc11(x))\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=1, padding=2)\n",
        "        x = F.leaky_relu(self.fc12(x))\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=1, padding=2)\n",
        "        x = F.leaky_relu(self.fc13(x))\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=1, padding=2)\n",
        "        x = F.leaky_relu(self.fc14(x))\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=1, padding=2)\n",
        "        x = F.leaky_relu(self.fc15(x))\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=1, padding=2)\n",
        "        x = F.leaky_relu(self.fc16(x))\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = PetitNet()\n",
        "model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
        "losslayer = nn.CrossEntropyLoss()\n",
        "batchsize = 50\n",
        "\n",
        "import collections\n",
        "memoryofloss = collections.deque(maxlen=200)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcOrsIhSmMhQ",
        "colab_type": "text"
      },
      "source": [
        "Lancer le code d'apprentissage ci dessous - comme il devrait prendre 5 mins, vous pouvez chercher à comprendre ce qu'il fait pendant qu'il tourne"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nza1RrjZmJ4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75f756cb-2f70-471f-f6a8-cd4fdbbccd34"
      },
      "source": [
        "for iteration in range(5000):\n",
        "    model.train()\n",
        "    model.cuda()\n",
        "    \n",
        "    X,Y = shuffle(X,Y)\n",
        "    Ybatch = np.stack(Y[0:batchsize])\n",
        "    Z = model(torch.Tensor(np.stack(X[0:batchsize])).cuda())\n",
        "        \n",
        "    # move from BATCH x NB CLASSES x 8192 to 409600 x NB CLASSES\n",
        "    Z = torch.transpose(Z,1,2)\n",
        "    Z = Z.contiguous().view(409600,3)\n",
        "    Ybatch = Ybatch.flatten()\n",
        "    Ybatch = torch.from_numpy(Ybatch).long().cuda()\n",
        "    \n",
        "    loss = losslayer(Z,Ybatch)\n",
        "    \n",
        "    memoryofloss.append(loss.cpu().data.numpy())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if iteration%100==99:\n",
        "        print(sum(memoryofloss)/len(memoryofloss))\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            model.cpu()\n",
        "            print(eval_model(Xtest,Ytest,model))\n",
        "            print(eval_model(X,Y,model))\n",
        "            torch.save(model,\"model.ptz\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0732719111442566\n",
            "(0.4043017228049902, array([[    0,    28, 42301],\n",
            "       [    0,   468, 30870],\n",
            "       [    0,     0, 49213]]))\n",
            "(0.42988358576987606, array([[     0,   5308, 226289],\n",
            "       [     0,  11998, 182118],\n",
            "       [     0,   6620, 304947]]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type PetitNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm1d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv1d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.0266095313429833\n",
            "(0.5166054963745412, array([[ 2541,   379, 39409],\n",
            "       [ 1096, 11980, 18262],\n",
            "       [   12,   241, 48960]]))\n",
            "(0.5569735284104703, array([[ 19592,   6332, 205673],\n",
            "       [  9879,  97226,  87011],\n",
            "       [  3462,  14277, 293828]]))\n",
            "0.9183169382810593\n",
            "(0.6566108674245815, array([[10938,   794, 30597],\n",
            "       [ 1300, 21152,  8886],\n",
            "       [  101,   517, 48595]]))\n",
            "(0.6451841292532969, array([[ 62094,   9102, 160401],\n",
            "       [  9963, 130342,  53811],\n",
            "       [  8361,  19960, 283246]]))\n",
            "0.8054304102063179\n",
            "(0.7313417045759719, array([[27962,   971, 13396],\n",
            "       [ 1317, 20705,  9316],\n",
            "       [ 7476,   536, 41201]]))\n",
            "(0.7235151862044458, array([[154590,  10773,  66234],\n",
            "       [ 15267, 143390,  35459],\n",
            "       [ 59445,  16668, 235454]]))\n",
            "0.7191143706440926\n",
            "(0.7440531896713081, array([[25170,  1216, 15943],\n",
            "       [  874, 21834,  8630],\n",
            "       [ 4073,   714, 44426]]))\n",
            "(0.752586869863729, array([[138946,  11227,  81424],\n",
            "       [ 12025, 153656,  28435],\n",
            "       [ 30312,  18989, 262266]]))\n",
            "0.659179952442646\n",
            "(0.7488627208437432, array([[33257,  1104,  7968],\n",
            "       [ 1153, 21521,  8664],\n",
            "       [10926,  1044, 37243]]))\n",
            "(0.7740156059901178, array([[168720,   9878,  52999],\n",
            "       [ 15558, 155587,  22971],\n",
            "       [ 45134,  20073, 246360]]))\n",
            "0.6090584886074066\n",
            "(0.7661884262009586, array([[33764,  1467,  7098],\n",
            "       [  733, 21680,  8925],\n",
            "       [ 9215,  1292, 38706]]))\n",
            "(0.7796932241574108, array([[177870,  10826,  42901],\n",
            "       [ 13041, 160069,  21006],\n",
            "       [ 51397,  23256, 236914]]))\n",
            "0.5669956278800964\n",
            "(0.7670103596162141, array([[32539,  1290,  8500],\n",
            "       [ 1458, 20274,  9606],\n",
            "       [ 6875,   900, 41438]]))\n",
            "(0.7798926053973994, array([[168713,   9635,  53249],\n",
            "       [ 11711, 151964,  30441],\n",
            "       [ 38616,  18628, 254323]]))\n",
            "0.5422005318105221\n",
            "(0.7177838722015608, array([[32465,   757,  9107],\n",
            "       [ 1694, 19381, 10263],\n",
            "       [11995,   862, 36356]]))\n",
            "(0.7607642133731914, array([[168703,   7790,  55104],\n",
            "       [ 22620, 148767,  22729],\n",
            "       [ 51059,  17081, 243427]]))\n",
            "0.5212847572565079\n",
            "(0.783994270879957, array([[39077,   500,  2752],\n",
            "       [ 1475, 22334,  7529],\n",
            "       [13903,   383, 34927]]))\n",
            "(0.7911298405899515, array([[199651,   6293,  25653],\n",
            "       [ 20684, 156318,  17114],\n",
            "       [ 66629,  17622, 227316]]))\n",
            "0.48788597449660304\n",
            "(0.7911149811606351, array([[35264,  1078,  5987],\n",
            "       [ 1960, 23488,  5890],\n",
            "       [ 7560,  3192, 38461]]))\n",
            "(0.8349815063727398, array([[188052,  10176,  33369],\n",
            "       [ 10478, 169326,  14312],\n",
            "       [ 30358,  22971, 258238]]))\n",
            "0.46062695935368536\n",
            "(0.7972509989339279, array([[33900,  1758,  6671],\n",
            "       [ 1833, 23634,  5871],\n",
            "       [ 6071,  2709, 40433]]))\n",
            "(0.8309559041939234, array([[174677,  15482,  41438],\n",
            "       [  4483, 175990,  13643],\n",
            "       [ 25039,  24547, 261981]]))\n",
            "0.4432031874358654\n",
            "(0.8159682945288531, array([[35404,   729,  6196],\n",
            "       [ 1640, 22788,  6910],\n",
            "       [ 6418,   720, 42075]]))\n",
            "(0.8386585304653178, array([[192155,   6624,  32818],\n",
            "       [ 11136, 160466,  22514],\n",
            "       [ 31593,  14268, 265706]]))\n",
            "0.4259782117605209\n",
            "(0.8026139110196043, array([[31030,  2148,  9151],\n",
            "       [  348, 25999,  4991],\n",
            "       [ 5801,  1815, 41597]]))\n",
            "(0.8318754993008093, array([[171401,  12457,  47739],\n",
            "       [  5081, 170301,  18734],\n",
            "       [ 21189,  18754, 271624]]))\n",
            "0.4135951015353203\n",
            "(0.8111099356287791, array([[33888,  1014,  7427],\n",
            "       [ 1478, 24148,  5712],\n",
            "       [ 5177,  2402, 41634]]))\n",
            "(0.8530424627787777, array([[184305,   8226,  39066],\n",
            "       [  6186, 172798,  15132],\n",
            "       [ 21747,  17991, 271829]]))\n",
            "0.4020762526988983\n",
            "(0.7815284706341908, array([[38768,   821,  2740],\n",
            "       [ 1939, 22011,  7388],\n",
            "       [12569,  1388, 35256]]))\n",
            "(0.8540434379836181, array([[210755,   5785,  15057],\n",
            "       [ 10825, 166592,  16699],\n",
            "       [ 45213,  14031, 252323]]))\n",
            "0.3918018999695778\n",
            "(0.7899187018334811, array([[35278,   568,  6483],\n",
            "       [ 2143, 21700,  7495],\n",
            "       [ 6337,  2788, 40088]]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-170e9c052481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"model.ptz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-d85574f32a24>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(X, Y, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-2a1dc770ea26>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    201\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 202\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pYMh-6PptYn",
        "colab_type": "text"
      },
      "source": [
        "Le code correspond juste à faire une boucle, dans laquelle on prend un bloc de données (batch), on le fait passer dans le réseau (ça produit Z). Après, il y a un peu de truc bizarre pour remettre les variables dans le bon format, mais ce qui compte c'est qu'on calcule une loss entre Z les prédictions et Y ce qu'on veut.\n",
        "Puis, on fait une descente de gradient.\n",
        "\n",
        "Mais ici, ça ne marche pas : le réseau n'est pas assez expressif - il n'est ni bon sur la base d'apprentissage - ni sur celle de test (s'il était bon sur celle d'apprentissage mais pas de test, il n'y aurait pas beaucoup d'espoir - mais là si).\n",
        "\n",
        "**Rajouter des couches (convolution et pooling) pour que ça marche mieux.**\n",
        "\n",
        "Vous pouvez aussi rajouter des prétraitements pour homogénéiser les données (centrer les données, etc) à la main et/ou via des couches de normalisation.\n",
        "\n",
        "Vous pouvez aussi aller jouer avec https://playground.tensorflow.org qui propose la même chose en plus jolie sur des données vectorielles (des points 2D, ici on a un signal temporel)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWLgQzRys1-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "04ab348a-99f1-4aa6-c6b3-7899061825f1"
      },
      "source": [
        "model = torch.load(\"model.ptz\")\n",
        "print(eval_model(Xtest,Ytest,model))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.7815284706341908, array([[38768,   821,  2740],\n",
            "       [ 1939, 22011,  7388],\n",
            "       [12569,  1388, 35256]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N1mN-sosyHw",
        "colab_type": "text"
      },
      "source": [
        "##Les réseaux récurrents\n",
        "\n",
        "Passons maintenant aux réseaux récurrents.\n",
        "En tant qu'utilisateur, utiliser un réseau récurrent consiste simplement à remplacer une partie des convolutions par un LSTM et/ou un GRU.\n",
        "\n",
        "D'un point de vue théorique, cela permet de réduire le nombre de paramètre pour un horizon temporel donné. Et, à performance égales, il y a une prime à l'utilisation de LSTM pour publier.\n",
        "\n",
        "Maintenant, *est ce que réduire le nombre de paramétre c'est mieux en pratique  ?*\n",
        "Malheureusement, *p'têt ben qu'oui, p'têt ben qu'non*, le mieux c'est d'essayer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ8lx8OWSwAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PetitNetRecurrent(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PetitNetRecurrent, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=2, hidden_size=128, num_layers=2)\n",
        "        self.outputprob = nn.Conv1d(128, 3, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        xTBF = torch.transpose(x,1,2)\n",
        "        xTBF = torch.transpose(xTBF,0,1)\n",
        "        \n",
        "        lstmoutput,_ = self.lstm(xTBF)\n",
        "        xBFT = torch.transpose(lstmoutput,0,1)\n",
        "        xBFT = torch.transpose(xBFT,1,2)\n",
        "\n",
        "        x = self.outputprob(xBFT)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p16lfWJVTros",
        "colab_type": "text"
      },
      "source": [
        "Vous remarquerez que le réseau a besoin d'opérations de transposition car le LSTM n'a pas le même format d'entrée qu'une convolution (trop facile sinon...) : la convolution attend des données Batch x Feature x Temps alors que le lstm attend des données Temps x Batch x Feature.\n",
        "\n",
        "**faites le code d'apprentissage correspondant et tester ce mini réseau**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v1dyFVUTq7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svjk6C-rU22R",
        "colab_type": "text"
      },
      "source": [
        "Normalement, 1 seul LSTM ne devrait pas suffire, vous pouvez soit augmenter le nombre et la taille des couches cachées, soit combiner lstm et convolution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atkpbitoVHYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}