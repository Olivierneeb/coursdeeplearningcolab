{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tplstm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/tplstm_convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sX-k16KRvZiY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TP LSTM\n",
        "\n",
        "la liste des paquets nécessaires au programme\n"
      ]
    },
    {
      "metadata": {
        "id": "Lbev5unYvOVG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.autograd\n",
        "import torch.autograd.variable\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z0pCycDRvszu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "définition d'un générateur aléatoire de signaux :  \n",
        "* classe 0 -> rampe décroissante\n",
        "* classe 1 -> constante\n",
        "* classe 2 -> rampe croissante\n",
        "\n",
        "auquel on ajoute un bruit uniforme de grande intensité\n",
        "\n",
        "**l'objectif est d'être capable de prédire en chaque point s'il fait parti de la classe 0, 1 ou 2 (sachant qu'il y a des ambiguités à cause du bruit)**"
      ]
    },
    {
      "metadata": {
        "id": "xoNyIVQP0ONI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "N = 1\n",
        "T = 400\n",
        "def generateSample():\n",
        "    #generating gt and corresponding\n",
        "    y = np.zeros((T,N),dtype=int)\n",
        "    signal = np.zeros((T,N,1),dtype=int)\n",
        "    for n in range(N):\n",
        "        t=1\n",
        "        while t<T:\n",
        "            Dt = random.randint(10,40)\n",
        "            classe = random.randint(0,2)\n",
        "            while y[t-1][n]==classe and classe!=1:\n",
        "                classe = random.randint(0,2)    \n",
        "            for dt in range(Dt):\n",
        "                if t+dt<T:\n",
        "                    y[t+dt][n] = classe\n",
        "                    signal[t+dt][n][0] = (dt+1)*(classe-1)\n",
        "            t+=Dt\n",
        "    \n",
        "    #generating pure noise          \n",
        "    x = np.random.randint(-6,7,size=(T,N,1))\n",
        "\n",
        "    #adding the signal\n",
        "    x += signal\n",
        "    x = np.maximum(x,np.ones((T,N,1),dtype=int)*(-20))\n",
        "    x = np.minimum(x,np.ones((T,N,1),dtype=int)*19)\n",
        "    x += 20\n",
        "    \n",
        "    return x,y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pIdprpjM1rxX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "fonction de visualisation des signaux - de la classe et de la prédiction \n",
        "* vert pour la classe 0\n",
        "* bleu pour la classe 1\n",
        "* rose pour la classe 2"
      ]
    },
    {
      "metadata": {
        "id": "mdPJdl-615FO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualizecurve(x,y,z):\n",
        "    grid = np.ones((40*N,T,3),dtype=int)*255\n",
        "\n",
        "    for n in range(N):\n",
        "        for t in range(T):\n",
        "            if y[t][n]==0:\n",
        "                grid[40*n:40*n+20,t,:] = np.asarray([207,236,207])\n",
        "            if y[t][n]==1:\n",
        "                grid[40*n:40*n+20,t,:] = np.asarray([204,236,239])\n",
        "            if y[t][n]==2:\n",
        "                grid[40*n:40*n+20,t,:] = np.asarray([221,212,232])\n",
        "                \n",
        "            if z[t][n]==0:\n",
        "                grid[40*n+20:40*n+40,t,:] = np.asarray([207,236,207])\n",
        "            if z[t][n]==1:\n",
        "                grid[40*n+20:40*n+40,t,:] = np.asarray([204,236,239])\n",
        "            if z[t][n]==2:\n",
        "                grid[40*n+20:40*n+40,t,:] = np.asarray([221,212,232])\n",
        "            \n",
        "            grid[40*n+x[t][n]][t] = np.zeros(3,dtype=int)\n",
        "            \n",
        "    return np.uint8(grid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i4TOh4Lb2r9e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "convolution"
      ]
    },
    {
      "metadata": {
        "id": "6T8uzric25Kj",
        "colab_type": "code",
        "outputId": "cba80df4-ab9f-4db1-9f56-5fca0fae515e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.output1 = nn.Conv1d(1,3, kernel_size=5, bias=True,padding=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        T,N,_ = x.shape\n",
        "        \n",
        "        #case N=1 remove N axis\n",
        "        x = x[:,0,0]\n",
        "        #now shape is (T)\n",
        "        \n",
        "        alloutput = []\n",
        "        vx = torch.autograd.Variable(torch.Tensor(np.expand_dims(np.expand_dims(x,axis=0),axis=0)).float()) #convolution 1D expects a 3D tensor N x 1 x T\n",
        "        output = self.output1(vx)\n",
        "        for t in range(T):\n",
        "            alloutput.append(output[:,:,t])\n",
        "            \n",
        "        return alloutput\n",
        "\n",
        "    def forwardnp(self,x):\n",
        "        T,N,_ = x.shape\n",
        "        \n",
        "        alloutput = self.forward(x)\n",
        "        \n",
        "        npprob = np.zeros((T,N,3),dtype=float)\n",
        "        for t in range(T): \n",
        "            npprob[t] = alloutput[t].cpu().data.numpy()\n",
        "        \n",
        "        pred = np.argmax(npprob,axis=2)\n",
        "        return pred,npprob\n",
        "\n",
        "model = Net()\n",
        "model.train()\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (output1): Conv1d(1, 3, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "Tb4zLxtm3Kp1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "l'apprentissage et les paramètres associés"
      ]
    },
    {
      "metadata": {
        "id": "H-vzcjZj3P_w",
        "colab_type": "code",
        "outputId": "29216c8d-01c7-429c-c250-62c9519ff759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        }
      },
      "cell_type": "code",
      "source": [
        "lr = 0.00001\n",
        "momentum = 0.5\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "losslayer = nn.CrossEntropyLoss()\n",
        "\n",
        "from IPython.display import clear_output # command to clear the figures\n",
        "from time import sleep\n",
        "\n",
        "allprints = []\n",
        "nbepoch = 200\n",
        "for epoch in range(nbepoch):\n",
        "    x,y=generateSample()\n",
        "    \n",
        "    alloutput = model(x)\n",
        "\n",
        "    npprob = np.zeros((T,N,3),dtype=float)\n",
        "    for t in range(T): \n",
        "        npprob[t] = alloutput[t].cpu().data.numpy()\n",
        "    z = np.argmax(npprob,axis=2)\n",
        "\n",
        "    allloss = []\n",
        "    for t in range(T):\n",
        "        targett = torch.autograd.Variable(torch.from_numpy(y[t]).long())\n",
        "        losst = losslayer(alloutput[t], targett)\n",
        "        allloss.append(losst)\n",
        "\n",
        "    loss = sum(allloss)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch%8==0:\n",
        "        #show how it learn\n",
        "        nberror = (np.transpose(np.nonzero(y-z))).shape[0]\n",
        "        allprints.append((\"error=\",nberror,\"\\toptimisation loss=\", loss.cpu().data.numpy()))\n",
        "        visu = visualizecurve(x[:,:,0],y,z)\n",
        "        clear_output()\n",
        "        plt.imshow(visu)\n",
        "        plt.show()\n",
        "        for a,b,c,d in allprints:\n",
        "            print(a,b,c,d)\n",
        "        sleep(1)\n",
        " \n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABECAYAAACPp/75AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nslit4RTROgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "error= 275 \toptimisation loss= 2559.6758\n",
            "error= 219 \toptimisation loss= 699.8359\n",
            "error= 286 \toptimisation loss= 1036.9371\n",
            "error= 214 \toptimisation loss= 903.4503\n",
            "error= 255 \toptimisation loss= 622.9668\n",
            "error= 201 \toptimisation loss= 945.31146\n",
            "error= 265 \toptimisation loss= 735.94794\n",
            "error= 257 \toptimisation loss= 444.28656\n",
            "error= 306 \toptimisation loss= 848.708\n",
            "error= 225 \toptimisation loss= 461.17783\n",
            "error= 232 \toptimisation loss= 645.9635\n",
            "error= 284 \toptimisation loss= 931.4159\n",
            "error= 162 \toptimisation loss= 1190.6204\n",
            "error= 262 \toptimisation loss= 541.44696\n",
            "error= 239 \toptimisation loss= 884.6583\n",
            "error= 237 \toptimisation loss= 751.38556\n",
            "error= 285 \toptimisation loss= 1053.1611\n",
            "error= 301 \toptimisation loss= 833.0054\n",
            "error= 239 \toptimisation loss= 410.5773\n",
            "error= 218 \toptimisation loss= 416.60266\n",
            "error= 273 \toptimisation loss= 898.7608\n",
            "error= 228 \toptimisation loss= 432.34335\n",
            "error= 239 \toptimisation loss= 536.7355\n",
            "error= 248 \toptimisation loss= 452.38788\n",
            "error= 318 \toptimisation loss= 527.23804\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}