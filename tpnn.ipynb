{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/tpnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiLsAyIhStUn",
        "colab_type": "text"
      },
      "source": [
        "# TP réseau de neurones\n",
        "\n",
        "### Objectif\n",
        "L'objectif de ce tp est de se familiariser avec la paradigme essentielle de l'apprentissage par ordinateur : une base d'apprentissage pour apprendre et une base de test pour évaluer.\n",
        "\n",
        "### Demarche\n",
        "La demarche repose principalement sur la recherche de jeux de données apprentissage et test sur lesquels un algorithme fixé a un comportement demandé.\n",
        "\n",
        "Indépendamment, l'ensemble du code étant modifiable, il invite à être modifié (l'algorithme principal peut notamment être remplacé par un plus proche voisin) pour explorer différemment ces notions. De plus la selection de la répartition train/test peut être faites aléatoirement à partir d'une distribution fixe.\n",
        "\n",
        "### À noter\n",
        "À noter qu'une version beaucoup plus \"cool\" peut être trouvé ici : https://playground.tensorflow.org avec le désavantage de mettre l'accent sur le réseau et non sur les données comme c'est l'objectif ici.\n",
        "\n",
        "Néanmoins, compte tenu de la qualité de cette application (n'est pas google qui veut), le tp peut +/- être fait sur ce site plutôt que dans ce notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1SZHHMEIDZZ",
        "colab_type": "text"
      },
      "source": [
        "## La boite noire\n",
        "\n",
        "L'ensemble des fonctions ci dessous n'est pas voué à être comprise/modifié en première lecture.\n",
        "Cela implémente une fonction qui étant donnée une base d'apprentissage et une base de test, réalise une apprentissage et une évaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGthUy4HS2ju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.autograd\n",
        "import torch.autograd.variable\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import animation\n",
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "def visualize_current_model_behaviour(trainingdata,testingdata,model):\n",
        "    data = {}\n",
        "    data[\"train\"] = trainingdata\n",
        "    data[\"test\"] = testingdata\n",
        "    \n",
        "    grid = {}\n",
        "    grid[\"train\"] = np.ones((50,50,3),dtype=int)\n",
        "    grid[\"test\"] = np.ones((50,50,3),dtype=int)\n",
        "    for traintest in [\"train\",\"test\"]:\n",
        "        X,Y = data[traintest]\n",
        "        for i in range(X.shape[0]):\n",
        "            row,col = X[i][0],X[i][1]\n",
        "            if Y[i]==1:\n",
        "                grid[traintest][row][col][0]=0\n",
        "                grid[traintest][row][col][2]=0\n",
        "            else:\n",
        "                grid[traintest][row][col][0]=0\n",
        "                grid[traintest][row][col][1]=0\n",
        "    \n",
        "    grid[\"alldata\"] = grid[\"train\"]*grid[\"test\"]\n",
        "    \n",
        "    batch = np.zeros((50*50,2),dtype=float)\n",
        "    for row in range(50):\n",
        "        for col in range(50):\n",
        "            batch[row*50+col][0]=row\n",
        "            batch[row*50+col][1]=col\n",
        "    prediction = model.getPredictedClass(batch)\n",
        "    \n",
        "    \n",
        "    grid[\"pred\"] = np.ones((50,50,3),dtype=int)*255\n",
        "    for row in range(50):\n",
        "        for col in range(50):\n",
        "            if prediction[row*50+col] == 1:\n",
        "                grid[\"pred\"][row][col][0]=175\n",
        "                grid[\"pred\"][row][col][2]=175\n",
        "            else:\n",
        "                grid[\"pred\"][row][col][0]=175\n",
        "                grid[\"pred\"][row][col][1]=175\n",
        "    \n",
        "    grid[\"train_error\"] = np.ones((50,50,3),dtype=int)*255\n",
        "    grid[\"test_error\"] = np.ones((50,50,3),dtype=int)*255\n",
        "    for traintest in [\"train\",\"test\"]:\n",
        "        X,Y = data[traintest]\n",
        "        for i in range(X.shape[0]):\n",
        "            row,col = X[i][0],X[i][1]\n",
        "            if prediction[row*50+col] != Y[i]:\n",
        "                grid[traintest+\"_error\"][row][col][1]=0\n",
        "                grid[traintest+\"_error\"][row][col][2]=0\n",
        "    \n",
        "    for key in grid:\n",
        "        grid[key][0,:,:]=0\n",
        "        grid[key][49,:,:]=0\n",
        "        grid[key][:,0,:]=0\n",
        "        grid[key][0,49,:]=0\n",
        "    \n",
        "    tmp = np.concatenate((grid[\"alldata\"]*255,grid[\"train\"]*255,grid[\"test\"]*255), axis=1)\n",
        "    tmp2 = np.concatenate((grid[\"pred\"],grid[\"train_error\"],grid[\"test_error\"]), axis=1)\n",
        "    tmp3 = np.concatenate((tmp,tmp2),axis=0)\n",
        "    return tmp3\n",
        "\n",
        "\n",
        "def train_test_deep_network(trainingdata,testingdata,model,nbIteration):\n",
        "    model.updateweights(trainingdata)\n",
        "\n",
        "    for iteration in range(nbIteration-1):\n",
        "        loss = model.updateweights(trainingdata)\n",
        "        \n",
        "        if iteration%50==0:\n",
        "          visu = visualize_current_model_behaviour(trainingdata,testingdata,model)\n",
        "\n",
        "          clear_output()\n",
        "          plt.imshow(visu)\n",
        "          plt.show()\n",
        "          sleep(3)\n",
        "\n",
        "\n",
        " \n",
        "class Net(nn.Module):\n",
        "    def getPredictedClass(self,x):\n",
        "        variablex = torch.autograd.Variable(torch.Tensor(x.astype(float)))\n",
        "        variableoutput = self.forward(variablex)\n",
        "        prob = variableoutput.cpu().data.numpy()\n",
        "        return np.argmax(prob,axis=1)\n",
        "    \n",
        "    def updateweights(self,batchfromtrain):\n",
        "        x,y = batchfromtrain\n",
        "        variablex = torch.autograd.Variable(torch.Tensor(x.astype(float)))\n",
        "        variabley = torch.autograd.Variable(torch.from_numpy(y).long())\n",
        "        variableoutput = self.forward(variablex)\n",
        "        \n",
        "        loss = self.losslayer(variableoutput,variabley)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()        \n",
        "        return loss.cpu().data.numpy()\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 30, bias=True)\n",
        "        self.fc2 = nn.Linear(30, 30, bias=True)\n",
        "        self.fc2bis = nn.Linear(30, 30, bias=True)\n",
        "        self.fc3 = nn.Linear(30, 2, bias=True)\n",
        "        \n",
        "        self.train()\n",
        "        \n",
        "        \n",
        "        self.lr = 0.1\n",
        "        self.momentum = 0.5\n",
        "        self.optimizer = optim.SGD(self.parameters(), lr=self.lr, momentum=self.momentum)\n",
        "        self.losslayer = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x/30))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = F.leaky_relu(self.fc2bis(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "        \n",
        "class NearestNeighbourg:\n",
        "    def getPredictedClass(self,x):\n",
        "        if len(x.shape)==1:        \n",
        "            distances = [(np.sum((x-self.X[i])*(x-self.X[i])),i) for i in range(self.X.shape[0])]\n",
        "            d,argmin = min(distances)\n",
        "            return self.Y[argmin]\n",
        "        else:\n",
        "            y = [self.getPredictedClass(x[i]) for i in range(x.shape[0])]\n",
        "            return np.asarray(y)\n",
        "    \n",
        "    def updateweights(self,x,y):\n",
        "        self.X = x\n",
        "        self.Y = y \n",
        "\n",
        "\n",
        "def data_from_grid_label(gridlabel):\n",
        "    X,Y = [],[]\n",
        "    tmp = np.zeros((1,2),dtype=int)\n",
        "    for row in range(10):\n",
        "        for col in range(10):\n",
        "            tmp[0][0]=row*5+2\n",
        "            tmp[0][1]=col*5+2\n",
        "            if gridlabel[row][col] == '+':\n",
        "                X.append(tmp.copy())\n",
        "                Y.append(1)\n",
        "            if gridlabel[row][col] == '-':\n",
        "                X.append(tmp.copy())\n",
        "                Y.append(0)\n",
        "    return np.concatenate(X,axis=0),np.asarray(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OThTjp_hNR4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def observe_network_behaviour_on_griddata(gridlabeltrain,gridlabeltest):\n",
        "    model = Net()\n",
        "    trainingdata,testingdata = data_from_grid_label(gridlabeltrain),data_from_grid_label(gridlabeltest)\n",
        "    train_test_deep_network(trainingdata,testingdata,model,300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUQcfvqCS62P",
        "colab_type": "text"
      },
      "source": [
        "## Exemples d'apprentissage :\n",
        "\n",
        "Faites tourner les 3 apprentissages ci dessous pour vous familiariser avec le code\n",
        "\n",
        "### CAS 1 : linéaire"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI37qd1cVyJD",
        "colab_type": "code",
        "outputId": "c592fa89-99eb-40ca-89a0-02af661c20f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "train = [\n",
        "['-','-','-','-','-','-','-','-','-','-'],\n",
        "['-','-','-','-','-','-','-','-','-','-'],\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' '],\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' '],\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' '],\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' '],\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' '],\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' '],\n",
        "['+','+','+','+','+','+','+','+','+','+'],\n",
        "['+','+','+','+','+','+','+','+','+','+']]\n",
        "\n",
        "test = [\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' '],\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' '],\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' '],\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' '],\n",
        "['-','-','-','-','-','-','-','-','-','-'],\n",
        "['-','-','-','-','-','-','-','-','-','-'],\n",
        "['+','+','+','+','+','+','+','+','+','+'],\n",
        "['+','+','+','+','+','+','+','+','+','+'],\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' '],\n",
        "[' ',' ',' ',' ',' ',' ',' ',' ',' ',' ']]\n",
        "\n",
        "observe_network_behaviour_on_griddata(train,test)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD8CAYAAACxUoU3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrCWpAcNakhowrCWpAcNakhowrCWpgf8H+/V8a8TvfVkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}