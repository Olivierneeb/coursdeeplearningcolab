{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/TP1_theorie_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTjvWNk7Kjmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torch.autograd\n",
        "import torch.autograd.variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgWO6beJKuvY",
        "colab_type": "text"
      },
      "source": [
        "L'objectif de ce tp est de manipuler les objets \"convolutions\" et \"pooling\".\n",
        "Nous ne traiteront pas d'images réelles (car les moyens informatiques à mettre en oeuvre sont complexes). Mais nous observerons l'effet de ces objets sur des tenseurs aléatoires.\n",
        "\n",
        "EN CAS DE DOUTE CONSULTER LA DOCUMENTATION SUR https://pytorch.org/\n",
        "\n",
        "N'hésitez pas à regarder sur internet les illustrations sur la convolution/pooling avec ou sans stride et padding (par example : https://github.com/vdumoulin/conv_arithmetic).\n",
        "\n",
        "Ici, on conservera l'esprit convolution <=> stride 1 // pooling <=> stride 2 (tous les réseaux classiques sauf la première convolution d'Alexnet et de Resnet)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWnsPDjLIKMf",
        "colab_type": "text"
      },
      "source": [
        "# Les convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF4_XciGK29r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = torch.rand((1,3,32,32))\n",
        "print(image.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63lH0MQLnaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv = nn.Conv2d(3,5,kernel_size = (5))\n",
        "print(conv.weight.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmyLLLP4MIRm",
        "colab_type": "text"
      },
      "source": [
        "**Q1 : À quoi correspondent les arguments de Conv2d ?** (regardez la doc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrXW3B80MFJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageApresConv = conv(image)\n",
        "print(imageApresConv.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNmjUVtWMYxj",
        "colab_type": "text"
      },
      "source": [
        "Ici, la convolution n'avait pas de padding, la taille de l'image est modifié... Généralement, on préfère que les convolutions aient du padding pour conserver la taille de l'image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCxx4_i6Mpfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convpadding = nn.Conv2d(3,5,kernel_size = (5),padding=2)\n",
        "print(convpadding.weight.shape)\n",
        "imageApresConvPadding = convpadding(image)\n",
        "print(imageApresConvPadding.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTFgr9lgM9Fz",
        "colab_type": "text"
      },
      "source": [
        "**Q2 : Comment transformeriez vous une image en 1 seul vecteur à l'aide d'une seule convolution ?** On veut un tenseur [1x5x1x1] en sortie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Sq3mgcNEm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "menO5kLfNHa_",
        "colab_type": "text"
      },
      "source": [
        "**Q3 : Combien de poids a cette convolution (vis à vis de l'image) ? Qu'elle différence avec un neurone classique dans ce cas ?**\n",
        "\n",
        "Si l'image faisait 64x64 pixel, quelle serait la taille qu'on obtiendrait ?\n",
        "Pareil si l'image faisait 128x128 pixel ? (vous pouvez coder pour tester si vous n'êtes pas sur)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcdIl9ZrJg3z",
        "colab_type": "text"
      },
      "source": [
        "**Q4 :**\n",
        "\n",
        "il n'y a aucun intérêt à avoir de si grosse convolution, généralement les convolutions sont petites - 3x3 avec padding - et combiné avec du pooling\n",
        "\n",
        "**Écrire une convolution 3x3 avec padding qui va donner une valeur très forte au niveau des pixels qui ont des valeurs plus fortes au dessus qu'en dessous (l'entrée est une image 1D la sortie aussi). Tester votre code sur des matrices aléatoires**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTYqW834Lf6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qHh5SyILm6F",
        "colab_type": "text"
      },
      "source": [
        "# Relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuNHq3PhL1Cx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = torch.rand((1,1,6,6))-0.5\n",
        "print(image)\n",
        "imagerelu = F.relu(image)\n",
        "print(imagerelu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq58bWhlMFG6",
        "colab_type": "text"
      },
      "source": [
        "**Q5 : Que fait la fonction relu ? Combinez là avec votre convolution \"dégradé de couleur vers le haut\".**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D_AwO58MPRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeg_CsKmIHVh",
        "colab_type": "text"
      },
      "source": [
        "# Les pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixdc2PRCNxp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = torch.rand((1,3,32,32))\n",
        "print(image.shape)\n",
        "imagepool = F.max_pool2d(image, kernel_size=2, stride=2)\n",
        "print(imagepool.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEPzmiQMKbdT",
        "colab_type": "text"
      },
      "source": [
        "**Q6 : Que fait le pooling ?\n",
        "Quel serait le résultat sur une image 64x64 ou 128x128 ?** (vous pouvez coder pour tester si vous n'êtes pas sur)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_B1DYv0K58q",
        "colab_type": "text"
      },
      "source": [
        "**Q7 : Transformer une image 128x128 en une image 1x1 en utilisant uniquement des des convolutions 3x3 avec padding suivi de pooling 2x2 et 1 convolution 4x4 sans padding.**\n",
        "\n",
        "**Combien de poids à ce réseau ? Calculer le ratio avec 1 convolution 128x128.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t20tkSrSMTZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB0zQfveLWDs",
        "colab_type": "text"
      },
      "source": [
        "# estimation du champs recepteur d'un réseau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTEbSGD1Mh08",
        "colab_type": "text"
      },
      "source": [
        "**Q8 :** \n",
        "\n",
        "Le code suivant permet de mesurer la taille du champs recepteur des 13 première couche du réseau VGG 16 (un réseau très classique - regarder sur internet). \n",
        "\n",
        "**Qu'est ce que vous pensez que ça signifie ?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spbNotfVIqfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmptyVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmptyVGG, self).__init__()\n",
        "        self.conv = nn.Conv2d(1,1,kernel_size = 3,padding=1,bias=False)\n",
        "        self.conv.weight.data = torch.ones(1,1,3,3)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        x = F.upsample(x,scale_factor=16)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def measureReceptivefield(model):\n",
        "    x = torch.torch.zeros(1,1,601,601)\n",
        "    x[0][0][0][0]=1\n",
        "    x = model(x)\n",
        "    i = 1\n",
        "    while x[0][0][i][i]>0:\n",
        "      i+=1\n",
        "    return i\n",
        "VGG = EmptyVGG()\n",
        "print(measureReceptivefield(VGG))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuDMPkDyTYbb",
        "colab_type": "text"
      },
      "source": [
        "**Q bonus : adapter le code pour calculer le champs récepteur d'un réseau UNET  (regarder sur internet).** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGA-tsYwTrSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}