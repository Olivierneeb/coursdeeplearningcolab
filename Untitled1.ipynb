{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTjvWNk7Kjmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torch.autograd\n",
        "import torch.autograd.variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgWO6beJKuvY",
        "colab_type": "text"
      },
      "source": [
        "L'objectif de ce tp est de manipuler les objets \"convolutions\" et \"pooling\".\n",
        "Nous ne traiteront pas d'images réelles (car les moyens informatiques à mettre en oeuvre sont complexes). Mais nous observerons l'effet de ces objets sur des tenseurs aléatoires.\n",
        "\n",
        "EN CAS DE DOUTE CONSULTER LA DOCUMENTATION SUR https://pytorch.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWnsPDjLIKMf",
        "colab_type": "text"
      },
      "source": [
        "# Les convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF4_XciGK29r",
        "colab_type": "code",
        "outputId": "d0b14282-d795-4ba8-bee7-68f314683cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image = torch.rand((1,3,32,32))\n",
        "print(image.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63lH0MQLnaw",
        "colab_type": "code",
        "outputId": "2f8ab894-9359-48d3-b817-267b5fb2ecd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "conv = nn.Conv2d(3,5,kernel_size = (5))\n",
        "print(conv.weight.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmyLLLP4MIRm",
        "colab_type": "text"
      },
      "source": [
        "**À quoi correspondent les arguments de Conv2d ?** (regardez la doc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrXW3B80MFJW",
        "colab_type": "code",
        "outputId": "383495a7-1f0d-4d5b-c2bd-884a3e2138a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "imageApresConv = conv(image)\n",
        "print(imageApresConv.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 5, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNmjUVtWMYxj",
        "colab_type": "text"
      },
      "source": [
        "Ici, la convolution n'avait pas de padding, la taille de l'image est modifié... Généralement, on préfère que les convolutions aient du padding pour conserver la taille de l'image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCxx4_i6Mpfs",
        "colab_type": "code",
        "outputId": "0abae82e-de09-46a8-be30-26b2f5360a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "convpadding = nn.Conv2d(3,5,kernel_size = (5),padding=2)\n",
        "print(convpadding.weight.shape)\n",
        "imageApresConvPadding = convpadding(image)\n",
        "print(imageApresConvPadding.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 5, 5])\n",
            "torch.Size([1, 5, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTFgr9lgM9Fz",
        "colab_type": "text"
      },
      "source": [
        "**Comment transformeriez vous une image en 1 seul vecteur à l'aide d'une seule convolution ?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Sq3mgcNEm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37b313ae-2e95-4612-981e-e7f92011e2e4"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TODO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "menO5kLfNHa_",
        "colab_type": "text"
      },
      "source": [
        "**Combien de poids a cette convolution (vis à vis de l'image) ? Qu'elle différence avec un neurone classique dans ce cas ?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5G9DLlkNTvy",
        "colab_type": "text"
      },
      "source": [
        "**Si l'image faisait 64x64 pixel, quelle serait la taille qu'on obtiendrait ?\n",
        "Pareil si l'image faisait 128x128 pixel ?** (vous pouvez coder pour tester si vous n'êtes pas sur)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcdIl9ZrJg3z",
        "colab_type": "text"
      },
      "source": [
        "**Écrire une convolution qui va donner une valeur très forte au niveau des pixels qui ont des valeurs plus fortes au dessus qu'en dessous (l'entrée est une image 1D la sortie aussi).** Tester votre code sur des matrices aléatoires "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTYqW834Lf6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qHh5SyILm6F",
        "colab_type": "text"
      },
      "source": [
        "# Relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuNHq3PhL1Cx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "2d014561-4fb4-469c-be1f-c1bf6f87a703"
      },
      "source": [
        "image = torch.rand((1,1,6,6))-0.5\n",
        "print(image)\n",
        "imagerelu = F.relu(image)\n",
        "print(imagerelu)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[-0.3892, -0.0855,  0.2033, -0.3437,  0.1120, -0.3628],\n",
            "          [-0.0928,  0.1323, -0.3611,  0.0384, -0.2615,  0.3545],\n",
            "          [-0.0721, -0.3509, -0.1241,  0.0029, -0.4698,  0.3931],\n",
            "          [-0.1838, -0.3005, -0.3613,  0.1605,  0.4156, -0.4406],\n",
            "          [ 0.2394, -0.3996,  0.4554, -0.4447,  0.3078,  0.4156],\n",
            "          [ 0.4176, -0.0733, -0.3273,  0.4950,  0.4553, -0.1605]]]])\n",
            "tensor([[[[0.0000, 0.0000, 0.2033, 0.0000, 0.1120, 0.0000],\n",
            "          [0.0000, 0.1323, 0.0000, 0.0384, 0.0000, 0.3545],\n",
            "          [0.0000, 0.0000, 0.0000, 0.0029, 0.0000, 0.3931],\n",
            "          [0.0000, 0.0000, 0.0000, 0.1605, 0.4156, 0.0000],\n",
            "          [0.2394, 0.0000, 0.4554, 0.0000, 0.3078, 0.4156],\n",
            "          [0.4176, 0.0000, 0.0000, 0.4950, 0.4553, 0.0000]]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq58bWhlMFG6",
        "colab_type": "text"
      },
      "source": [
        "**Que fait la fonction relu ? Combinez là avec votre convolution \"dégradé de couleur vers le haut\".**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D_AwO58MPRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeg_CsKmIHVh",
        "colab_type": "text"
      },
      "source": [
        "# Les pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixdc2PRCNxp3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bc5e6713-c1a1-42d2-9405-b737649b8032"
      },
      "source": [
        "image = torch.rand((1,3,32,32))\n",
        "print(image.shape)\n",
        "imagepool = F.max_pool2d(image, kernel_size=2, stride=2)\n",
        "print(imagepool.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 32, 32])\n",
            "torch.Size([1, 3, 16, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEPzmiQMKbdT",
        "colab_type": "text"
      },
      "source": [
        "**Que fait le pooling ?\n",
        "Quel serait le résultat sur une image 64x64 ou 128x128 ?** (vous pouvez coder pour tester si vous n'êtes pas sur)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_B1DYv0K58q",
        "colab_type": "text"
      },
      "source": [
        "**Transformer une image 127x127 en une image 1x1 en utilisant uniquement des pooling 2x2 et des convolutions 3x3 sans padding.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t20tkSrSMTZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB0zQfveLWDs",
        "colab_type": "text"
      },
      "source": [
        "# estimation du champs recepteur d'un réseau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTEbSGD1Mh08",
        "colab_type": "text"
      },
      "source": [
        "Le code suivant permet de mesurer la taille du champs recepteur des 13 première couche du réseau VGG 16 (un réseau très classique - regarder sur internet). Qu'est ce que vous pensez que ça signifie ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spbNotfVIqfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmptyVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmptyVGG, self).__init__()\n",
        "        self.conv = nn.Conv2d(1,1,kernel_size = 3,padding=1,bias=False)\n",
        "        self.conv.weight.data = torch.ones(1,1,3,3)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        x = F.upsample(x,scale_factor=16)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-_8VCv4O2G3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a104de3d-b57c-435b-f998-941d276a7dbd"
      },
      "source": [
        "def measureReceptivefield(model):\n",
        "    x = torch.torch.zeros(1,1,601,601)\n",
        "    x[0][0][0][0]=1\n",
        "    x = model(x)\n",
        "    i = 1\n",
        "    while x[0][0][i][i]>0:\n",
        "      i+=1\n",
        "    return i\n",
        "VGG = EmptyVGG()\n",
        "print(measureReceptivefield(VGG))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2404: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}