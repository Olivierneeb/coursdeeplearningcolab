{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/bow_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTUF2gpAcOr5"
      },
      "source": [
        "# TP Sac de mot\n",
        "\n",
        "L'objectif de ce tp est de coder une approche sac de mots : c'est ce qu'on faisait de mieux **avant** le deep learning.\n",
        "\n",
        "\n",
        "On va réutiliser MNIST que vous connaissez désormais.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGNwRuVjdE5W"
      },
      "source": [
        "## Création d'un dictionnaire\n",
        "\n",
        "On va extraire un ensemble dense de patch dans des images MNIST et appliquer K moyenne dessus, cela nous donnera un dictionnaire de patches !\n",
        "\n",
        "D'abord récupérons MNIST (avec torchvision -- juste par faciliter mais ce n'est pas pertinent)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouvhsCnwdPgm"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "transform_mnist = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((32,32)),\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "mnisttrain = torchvision.datasets.MNIST(\"./mnist\",train=True, transform=transform_mnist, download=True)\n",
        "trainloader = torch.utils.data.DataLoader(mnisttrain, batch_size=64, shuffle=True, num_workers=2)\n",
        "mnisttest = torchvision.datasets.MNIST(\"./mnist\",train=False, transform=transform_mnist, download=True)\n",
        "testloader = torch.utils.data.DataLoader(mnisttest, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "\n",
        "sample = next(iter(trainloader))[0]\n",
        "show(torchvision.utils.make_grid(sample))\n",
        "print(sample.shape)  ## 64 c'est le batch\n",
        "                        ## 1 c'est du gris -- sinon ce serait 3 pour du RGB\n",
        "                        ## 32x32 c'est pour la taille de l'image (petite ici)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gNOHjffefzg"
      },
      "source": [
        "**Q1** (moyen) : écrire une fonction qui extrait des patch 8x8 dans une image, les transforme en vecteur (flatten) et les mets dans une liste donnée en argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBPJ5pdmdghW"
      },
      "source": [
        "def extraitpatch2D(allpatch,inputs):\n",
        "  row = np.random.randint(0,32-8,size=10)\n",
        "  col = np.random.randint(0,32-8,size=10)\n",
        "  for i in range(row.shape[0]):\n",
        "    allpatch.append(inputs[row[i]:row[i]+8,col[i]:col[i]+8].copy().flatten())\n",
        "\n",
        "def extraitpatchinbatch(allpatch,inputs):\n",
        "  for i in range(inputs.shape[0]):\n",
        "      extraitpatch2D(allpatch,inputs[i][0].cpu().numpy())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iauL3XSqfISU"
      },
      "source": [
        "**ATTENTION :** en fait c'est vraiment consommateur de ressource d'extraire autant de patches...\n",
        "\n",
        "On vous fourniera une version qui tire au hasard des patchs à extraire (et qui repasse en numpy).\n",
        "\n",
        "**Q2 (facile)** : utiliser la fonction show64patches pour visualiser 64 patchs tirés au hasard et/ou les patchs extraits d'une image unique. Chacun apporte une information \"faible\" mais dans leur ensemble, on espère qu'ils encodent l'image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6CxcGFzCord"
      },
      "source": [
        "import random\n",
        "\n",
        "def show64patch(patches):\n",
        "  patches = [torch.Tensor(patches[i]) for i in range(64)]\n",
        "  patches = [patch.view(8,8) for patch in patches]\n",
        "  patches = [patch.unsqueeze(0) for patch in patches]\n",
        "  patches = torch.stack(patches)\n",
        "  show(torchvision.utils.make_grid(patches))\n",
        "\n",
        "tmp = []\n",
        "\n",
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0VqQCfVEhYr"
      },
      "source": [
        "**Q3 (facile)** Parcourer le dataset de train pour extraire \"l'ensemble\" des patchs de l'ensemble des images (normalement on utilise train **ET** test mais bon)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5GqZNlohsM3"
      },
      "source": [
        "\n",
        "print(\"TODO\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhlChYqxFjl8"
      },
      "source": [
        "**Q4 (moyen)** : Appliquer sklearn.cluster.KMeans pour créer un dictionnaire de 512 clusters\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
        "\n",
        "\n",
        "c'est normal si ça prend 10 mins !\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFrKO733GDrR"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "print(len(allpatch)) ## on a un gros problème Kmeans !! \n",
        "                     ## dimension des vecteurs 64, \n",
        "                     ## K = 512\n",
        "                     ## N = 600000\n",
        "\n",
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtunFS0S4qYQ"
      },
      "source": [
        "**Q5 (facile)** : avez vous utiliser les labels jusqu'à maintenant ??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR3KCn3g5i6W"
      },
      "source": [
        "Non pour l'instant on utilise que de la données !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ipypqT-iRb"
      },
      "source": [
        "del allpatch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plvLXR2-GH5B"
      },
      "source": [
        "## Encodage\n",
        "\n",
        "L'objectif maintenant est d'utiliser le dictionnaire pour créer une fonction qui prend une image en entrée et qui produit un histogramme H avec h_i qui correspond au nombre de fois qu'on a vu un patch qui se rattache au groupe \"i\" du dictionnaire !\n",
        "\n",
        "cette fois on extraira tous les patchs -- vu que de toute façon on va juste en conserver leur index\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6GqksktIDKe"
      },
      "source": [
        "print(kmeans.cluster_centers_.shape)\n",
        "\n",
        "def extractallpatch(allpatch,image):\n",
        "  for row in range(image.shape[0]-8):\n",
        "    for col in range(image.shape[1]-8):\n",
        "        allpatch.append(image[row:row+8,col:col+8].copy().flatten())\n",
        "\n",
        "def extraitallpatchinbatch(allpatch,inputs):\n",
        "  for i in range(inputs.shape[0]):\n",
        "      extractallpatch(allpatch,inputs[i][0].cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H3CXh6D_KAO"
      },
      "source": [
        "**Q6 (facile)** : écrivez une fonction qui prend une liste contenant des entiers de 0 à 512 et qui retourne un histogramme de taille 512 avec h[i] le nombre de i dans la liste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K-rPU0oAUoT"
      },
      "source": [
        "\n",
        "print(\"TODO\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5PcoVeWAhmB"
      },
      "source": [
        "**Q7 facile :** écrire une fonction qui trie les indices d'un tableau en fonction des valeurs associées"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABiuLW2kAsFo"
      },
      "source": [
        "\n",
        "print(\"TODO\")\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kd4iBZBZMGt"
      },
      "source": [
        "les patchs les plus commun sont probablement justes tout noir ou tout blanc, ils contiennent peu d'information...\n",
        "d'un autre coté, si un groupe contient 0 patch il n'est pas intéressant non plus\n",
        "\n",
        "Le code suivant récupère 3 indices contenant au moins 64 éléments sans qu'ils soient juste à coté..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M4_8J74Z_Dw"
      },
      "source": [
        "def get3index(histo):\n",
        "  tmp = [(histo[i],i) for i in range(len(histo))]\n",
        "  tmp = sorted(tmp)\n",
        "  i = 0\n",
        "  while tmp[i][0]<64:\n",
        "    i+=1\n",
        "  return tmp[i][1],tmp[i+4][1],tmp[i+8][1]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjYSI67oICOK"
      },
      "source": [
        "**Q8 (moyen)** : visualiser des patchs d'un même centroide (disons correspondant à 3 centres comme ci dessus)\n",
        "\n",
        "*regarder l'exemple donnée dans la doc de scikit -- il vous permet de voir comment avoir le label associé à un patch*\n",
        "\n",
        "*ATTENTION 1 seul show par case de notebook*\n",
        "\n",
        "le résultat des kmeans vous parait il pertinent ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOY5DzQmIurp"
      },
      "source": [
        "\n",
        "sample = next(iter(trainloader))[0]\n",
        "tmp = []\n",
        "\n",
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "267BbgCkcMKx"
      },
      "source": [
        "\n",
        "print(\"TODO\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtRDIVnVcNru"
      },
      "source": [
        "\n",
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYQNyKpJVdQT"
      },
      "source": [
        "**Q9 (moyen)** : écrire une fonction qui prend 1 image et produit l'histogramme associé"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-Ys7PxCWLF3"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNWsXptRI4V5"
      },
      "source": [
        "## Classification\n",
        "\n",
        "**Q BONUS (pas si dur mais à la limite des moyens de calcul)** : parcourir l'ensemble du dataset de train, produire et stocker l'ensemble des histogrammes, puis apprendre un MLP (2 couches) ou arbre ou SVM sur ces histogrammes -> utiliser plutôt des classifiers scikit learn \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
        "\n",
        "https://scikit-learn.org/stable/modules/tree.html#classification\n",
        "\n",
        "https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification\n",
        "\n",
        "\n",
        "Puis utiliser ce classifier sur les données de test -- (qu'il convient d'encoder au préalable)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRmPiA6pUg7O"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}