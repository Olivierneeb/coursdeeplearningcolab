{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/bow_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTUF2gpAcOr5"
      },
      "source": [
        "# TP Sac de mot\n",
        "\n",
        "L'objectif de ce tp est de coder une approche sac de mots : c'est ce qu'on faisait de mieux **avant** le deep learning.\n",
        "\n",
        "\n",
        "On va réutiliser MNIST que vous connaissez désormais.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGNwRuVjdE5W"
      },
      "source": [
        "## Création d'un dictionnaire\n",
        "\n",
        "On va extraire un ensemble DENSE de patch dans des images MNIST et appliquer K moyenne dessus, cela nous donnera un dictionnaire de patches !\n",
        "\n",
        "D'abord récupérons MNIST (avec torchvision -- juste par faciliter mais ce n'est pas pertinent)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouvhsCnwdPgm"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "transform_mnist = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((32,32)),\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "mnisttrain = torchvision.datasets.MNIST(\"./mnist\",train=True, transform=transform_mnist, download=True)\n",
        "trainloader = torch.utils.data.DataLoader(mnisttrain, batch_size=64, shuffle=True, num_workers=2)\n",
        "mnisttest = torchvision.datasets.MNIST(\"./mnist\",train=False, transform=transform_mnist, download=True)\n",
        "testloader = torch.utils.data.DataLoader(mnisttest, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "\n",
        "sample = next(iter(trainloader))[0]\n",
        "show(torchvision.utils.make_grid(sample))\n",
        "print(sample.shape)  ## 64 c'est le batch\n",
        "                        ## 1 c'est du gris -- sinon ce serait 3 pour du RGB\n",
        "                        ## 32x32 c'est pour la taille de l'image (petite ici)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gNOHjffefzg"
      },
      "source": [
        "**Q1** (moyen) : écrire une fonction qui extrait des patch 8x8 dans une image, les transforme en vecteur (flatten) et les mets dans une liste donnée en argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBPJ5pdmdghW"
      },
      "source": [
        "def extraitpatch2D(allpatch,inputs):\n",
        "  print(\"TODO\")\n",
        "\n",
        "def extraitpatchinbatch(allpatch,inputs):\n",
        "  for i in range(inputs.shape[0]):\n",
        "      extraitpatch2D(allpatch,inputs[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iauL3XSqfISU"
      },
      "source": [
        "**ATTENTION :** en fait c'est vraiment consommateur de ressource d'extraire autant de patches...\n",
        "\n",
        "On vous fourniera une version qui tire au hasard des patchs à extraire (et qui repasse en numpy).\n",
        "\n",
        "**Q2 (facile)** : visualiser 64 patchs tirés au hasard et/ou les patchs extraits d'une image unique. Chacun apporte une information \"faible\" mais dans leur ensemble, on espère qu'ils encodent l'image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6CxcGFzCord"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0VqQCfVEhYr"
      },
      "source": [
        "**Q3 (facile)** Parcourer le dataset de train pour extraire l'ensemble (avec prunning) des patchs de l'ensemble des images (normalement on utilise train **ET** test mais bon)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5GqZNlohsM3"
      },
      "source": [
        "allpatch = []\n",
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhlChYqxFjl8"
      },
      "source": [
        "**Q4 (moyen)** : Appliquer sklearn.cluster.KMeans pour créer un dictionnaire de 2048 clusters\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFrKO733GDrR"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plvLXR2-GH5B"
      },
      "source": [
        "## Encodage\n",
        "\n",
        "L'objectif maintenant est d'utiliser le dictionnaire pour créer une fonction qui prend une image en entrée et qui produit un histogramme H avec h_i qui correspond au nombre de fois qu'on a vu un patch qui se rattache au groupe \"i\" du dictionnaire !\n",
        "\n",
        "cette fois on extraira tous les patchs -- vu que de toute façon on va juste en conserver leur index\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6GqksktIDKe"
      },
      "source": [
        "def extractallpatch(image):\n",
        "  out = []\n",
        "  for row in range(image.shape[0]-8):\n",
        "    for col in range(image.shape[1]-8):\n",
        "        out.append(image[row:row+8,col:col+8].copy().flatten())\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjYSI67oICOK"
      },
      "source": [
        "\n",
        "**Q5 (moyen)** : regarder l'exemple donnée dans la doc de scikit -- il vous permet de voir comment avoir le label associé à un patch\n",
        "\n",
        "écrire une fonction qui prend 1 image et produit l'histogramme associé"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOY5DzQmIurp"
      },
      "source": [
        "def encodeimage(image):\n",
        "  print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNWsXptRI4V5"
      },
      "source": [
        "## Classification\n",
        "\n",
        "**Q6 (dur voire bonus)** : parcourir l'ensemble du dataset de train, produire et stocker l'ensemble des histogrammes, puis apprendre un MLP (2 couches) ou arbre ou  sur ces histogrammes !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3kDmxkRkODf"
      },
      "source": [
        "maintenant on definit le réseau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUPT6Psfd4K8"
      },
      "source": [
        "class MonReseau(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MonReseau, self).__init__()\n",
        "        \n",
        "        self.linear1 = nn.Linear(1024, 1024)\n",
        "        self.linear2 = nn.Linear(1024, 2048)\n",
        "        self.linear3 = nn.Linear(2048, 4096)\n",
        "\n",
        "        self.final = nn.Linear(4096,10)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,1024)  # l'image 1 x 32 x 32 devient un vecteur 1024\n",
        "        x = F.leaky_relu(self.linear1(x))\n",
        "        x = F.leaky_relu(self.linear2(x))\n",
        "        x = F.leaky_relu(self.linear3(x))\n",
        "        \n",
        "        x = self.final(x)\n",
        "        return x\n",
        "\n",
        "monreseau = MonReseau()\n",
        "monreseau = monreseau.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS5V0cb8lh6j"
      },
      "source": [
        "ensuite on définit les paramètres de l'apprentissage : \n",
        "- le solver\n",
        "- la loss\n",
        "- le nombre d'itérations ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqtnni_zlvXh"
      },
      "source": [
        "optimizer = optim.Adam(monreseau.parameters(), lr=0.00001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "nbepoch = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzlZ5ZnMl30q"
      },
      "source": [
        "l'apprentissage à proprement parler :\n",
        "- on itere sur les données\n",
        "- on les fait rentrer dans le réseau\n",
        "- on compare la sortie courante à la sortie voulue\n",
        "- on calcule le gradient \n",
        "- on actualise les poids pour que la sortie courante soit plus proche que la sortie voulue\n",
        "\n",
        "**ET ON PASSE SUR CUDA CAR SINON C'EST TROP LONG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7IU7veee3f6"
      },
      "source": [
        "import random\n",
        "for epoch in range(nbepoch):\n",
        "  monreseau.train()\n",
        "  print(\"epoch\", epoch)\n",
        "  for inputs, targets in trainloader:   ## on itere sur les données \n",
        "    inputs, targets = inputs.cuda(),targets.cuda()\n",
        "\n",
        "    mespredictions = monreseau(inputs)  ## on les fait rentrer dans le réseau\n",
        "    loss = criterion(mespredictions,targets)  ## on compare la sortie courante à la sortie voulue\n",
        "\n",
        "    loss.backward() ## le gradient -- la magie par rapport à comment c'était long en court :-)\n",
        "    optimizer.step() ## on actualise les poids pour que la sortie courante soit plus proche que la sortie voulue\n",
        "\n",
        "    if random.randint(0,90)==0:\n",
        "      print(\"\\tloss=\",loss) ## on affiche pour valider que ça diverge pas\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiCrUvECoTsx"
      },
      "source": [
        "Maintenant, on calcule la performance obtenue **en test**\n",
        "à travers la matrice de confusion\n",
        "Mij c'est le nombre de fois qu'une image de la classe i a été classé comme j"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUl-2z9FfRUG"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "monreseau.eval()\n",
        "cm = np.zeros((10,10),dtype=int)  ###### ATTENTION DE BIEN ME REMETTRE A ZERO\n",
        "with torch.no_grad():  ### ici pas besoin de calculer les gradients\n",
        "    for inputs, targets in testloader:\n",
        "        inputs = inputs.cuda()\n",
        "        outputs = monreseau(inputs)\n",
        "        _,pred = outputs.max(1)\n",
        "        cm += confusion_matrix(pred.cpu().numpy(),targets.cpu().numpy(),list(range(10)))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVwdq_nMqCR9"
      },
      "source": [
        "**Q1 (facile)** : calculer le taux de bonne classification (donc la diagonale sur le total)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XlQ7IltqA-o"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJRTEjvGqOTr"
      },
      "source": [
        "### CNN\n",
        "\n",
        "**Q2 (dur)** : maintenant il faut changer le réseau pour mettre des convolutions et donc traiter la spécificité des images plutôt que de considérer ça comme un vecteur.\n",
        "\n",
        "Dupliquer le code de \"MonReseau\" et implémenter lenet au lieu d'un simple mlp\n",
        "\n",
        "regarder la doc : https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "\n",
        "et regarder sur internet pour lenet vous aurez plein d'info !!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0UVDKw2opzd"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ83_W9Mr7Y4"
      },
      "source": [
        "Lancez maintenant un train/test\n",
        "\n",
        "vous pouvez réutiliser quasiment tel quel la boucle \"d'apprentissage\" -- elle ne dépend PAS du réseau (les paramètres pourraient peut être changer mais dans les grosses lignes c'est la même boucle)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUo9rJUUFJfe"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L82jBjtP-vwr"
      },
      "source": [
        "# CNN VS MLP\n",
        "\n",
        "Maintenant on va s'intéresser à la différence entre un mlp et un CNN\n",
        "\n",
        "\n",
        "on fait regarder ce que donne nos codes -- si on permute les pixels\n",
        "ce sera évidemment une permutation **FIXE** (ce sera la même pour toutes les images train et test) qu'on peut générer calculant une permutation des lignes et une des colonnes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb5cc28A_B4K"
      },
      "source": [
        "def computerandompermutation(n):\n",
        "\tout = list(range(n))\n",
        "\trandom.shuffle(out)\n",
        "\treturn out\n",
        "permrow,permcol = computerandompermutation(32),computerandompermutation(32)\n",
        "print(permrow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC2xtwaYsYxV"
      },
      "source": [
        "\n",
        "\n",
        "**Q3 (moyenne) :** Coder une fonction qui prends en argument une permutation et une image et qui permute ses pixels.\n",
        "\n",
        "\n",
        "*n'oubliez est pour permuter la valeur de x et y dans un tableau T il faut faire*\n",
        "- tmp = T[y]\n",
        "- T[y] = T[x]\n",
        "- T[x] = tmp\n",
        "\n",
        "(sinon on écrase une des 2 valeurs)\n",
        "\n",
        "commencer par permuter une image 32x32 et créer une fonction qui l'applique 64 fois sur un batch 64x1x32x32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyE-3bjp_TY8"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QfvV_3e_Sp_"
      },
      "source": [
        "**SIGNALEZ que vous avez fini la question ci dessus -- il est nécessaire d'utiliser un codage efficace des permutations pour continuer -- il vous sera fourni**\n",
        "\n",
        "\n",
        "**Q4 (facile) :**\n",
        "Regarder les images avant et après permutation -- pourriez vous (vous même) classer les images APRES permutation ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJWQUZmLEorH"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13gMLc6AEniu"
      },
      "source": [
        "**Q5 (facile)** :\n",
        "Qu'est ce que ça change pour le MLP ??\n",
        "-> relancer l'apprentissage/test en ajoutant cette permutation pour valider que ça ne change rien !\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUGDT9osEnU4"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUshMI-dEnIu"
      },
      "source": [
        "**Q6 (facile)** : relancer le lenet -> là ça va changer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ds_JZ4aupBC"
      },
      "source": [
        "print(\"TODO\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laPww2Bnurqy"
      },
      "source": [
        "**Q7 (moyenne) :** faites une fonction qui ajoute du bruit (pour chaque pixel, mettez le à 0 ou à 1 avec une petite probabilité - le bruit est différent pour chaque image train et test)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-caGUzxVE5Hs"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJzlLXTAEyql"
      },
      "source": [
        "**Q8 (facile)** : Regarder les images avant et après permutation -- pourriez vous (vous même) classer les images APRES permutation ??\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGiAvpKQEyh9"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CekiyPfhEz2U"
      },
      "source": [
        "**Q9 (facile)** : Tester le MLP et le CNN -> cette fois c'est le CNN qui devrait être \"plutôt\" invariant (le bruit est +/- filtré par la convolution) alors que le MLP devrait être gêné par le bruit !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTA3zrQyxphh"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYYZMfsixq7g"
      },
      "source": [
        "## conclusion\n",
        "\n",
        "**-> se souvenir que si on prend TOUS les problèmes, tous les algos de classification sont tous aussi mauvais**\n",
        "\n",
        "**-> ce qui compte c'est qu'ils soient adaptés aux données qu'on peut réellement rencontrer**\n",
        "\n",
        "**En comparant les images avec permutation des pixels vs avec un bruit... Vous pouvez comprendre pourquoi le CNN est plus adapté à l'image naturelle \n",
        "que le MLP !**"
      ]
    }
  ]
}