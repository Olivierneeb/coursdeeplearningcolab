{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOymJokaUNMGxV6GPW76oJt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/2020/basic_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTUF2gpAcOr5"
      },
      "source": [
        "# TP deep learning\n",
        "\n",
        "L'objectif de ce tp est de manipuler les algorithmes de deep learning.\n",
        "\n",
        "Cependant, il faut bien voir que tuner un réseau est une tache complexe principalement à cause du temps nécessaire pour réaliser un apprentissage...\n",
        "\n",
        "Aussi, l'axe choisi est d'insister sur la différence MLP vs CNN à travers des codes simples d'apprentissage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGNwRuVjdE5W"
      },
      "source": [
        "## MLP\n",
        "\n",
        "Tout d'abord, il existe seulement **2** grandes bibliothèques pour faire du CNN : pytorch (facebook) ou tensorflow (google)... Dans ce TP ce sera pytorch.\n",
        "\n",
        "Techniquement la partie MLP aurait pu être traité avec scikit-learn mais ce sera fait...\n",
        "\n",
        "donc déjà il faut importer pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouvhsCnwdPgm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gNOHjffefzg"
      },
      "source": [
        "Ensuite on va charger les données.\n",
        "\n",
        "**Normalement c'est genre 80% du temps de prendre en charge les données !**\n",
        "\n",
        "Mais là on va travailler sur des données simple (MNIST) mise en forme par pytorch !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBPJ5pdmdghW"
      },
      "source": [
        "transform_mnist = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((32,32)),\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "mnisttrain = torchvision.datasets.MNIST(\"./mnist\",train=True, transform=transform_mnist, download=True)\n",
        "trainloader = torch.utils.data.DataLoader(mnisttrain, batch_size=64, shuffle=True, num_workers=2)\n",
        "mnisttest = torchvision.datasets.MNIST(\"./mnist\",train=False, transform=transform_mnist, download=True)\n",
        "testloader = torch.utils.data.DataLoader(mnisttest, batch_size=64, shuffle=True, num_workers=2)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iauL3XSqfISU"
      },
      "source": [
        "Commençons par visualiser quelques images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5GqZNlohsM3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "\n",
        "sample = next(iter(trainloader))\n",
        "show(torchvision.utils.make_grid(sample[0]))\n",
        "print(sample[0].shape)  ## 64 c'est le batch\n",
        "                        ## 1 c'est du gris -- sinon ce serait 3 pour du RGB\n",
        "                        ## 32x32 c'est pour la taille de l'image (petite ici)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3kDmxkRkODf"
      },
      "source": [
        "maintenant on definit le réseau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUPT6Psfd4K8"
      },
      "source": [
        "class MonReseau(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MonReseau, self).__init__()\n",
        "        \n",
        "        self.linear1 = nn.Linear(1024, 1024)\n",
        "        self.linear2 = nn.Linear(1024, 2048)\n",
        "        self.linear3 = nn.Linear(2048, 4096)\n",
        "\n",
        "        self.final = nn.Linear(4096,10)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,1024)  # l'image 1 x 32 x 32 devient un vecteur 1024\n",
        "        x = F.leaky_relu(self.linear1(x))\n",
        "        x = F.leaky_relu(self.linear2(x))\n",
        "        x = F.leaky_relu(self.linear3(x))\n",
        "        \n",
        "        x = self.final(x)\n",
        "        return x\n",
        "\n",
        "monreseau = MonReseau()\n",
        "monreseau = monreseau.cuda()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS5V0cb8lh6j"
      },
      "source": [
        "ensuite on définit les paramètres de l'apprentissage : \n",
        "- le solver\n",
        "- la loss\n",
        "- le nombre d'itérations ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqtnni_zlvXh"
      },
      "source": [
        "optimizer = optim.Adam(monreseau.parameters(), lr=0.00001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "nbepoch = 5"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzlZ5ZnMl30q"
      },
      "source": [
        "l'apprentissage à proprement parler :\n",
        "- on itere sur les données\n",
        "- on les fait rentrer dans le réseau\n",
        "- on compare la sortie courante à la sortie voulue\n",
        "- on calcule le gradient \n",
        "- on actualise les poids pour que la sortie courante soit plus proche que la sortie voulue\n",
        "\n",
        "**ET ON PASSE SUR CUDA CAR SINON C'EST TROP LONG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7IU7veee3f6"
      },
      "source": [
        "import random\n",
        "for epoch in range(nbepoch):\n",
        "  monreseau.train()\n",
        "  print(\"epoch\", epoch)\n",
        "  for inputs, targets in trainloader:   ## on itere sur les données \n",
        "    inputs, targets = inputs.cuda(),targets.cuda()\n",
        "\n",
        "    mespredictions = monreseau(inputs)  ## on les fait rentrer dans le réseau\n",
        "    loss = criterion(mespredictions,targets)  ## on compare la sortie courante à la sortie voulue\n",
        "\n",
        "    loss.backward() ## le gradient -- la magie par rapport à comment c'était long en court :-)\n",
        "    optimizer.step() ## on actualise les poids pour que la sortie courante soit plus proche que la sortie voulue\n",
        "\n",
        "    if random.randint(0,90)==0:\n",
        "      print(\"\\tloss=\",loss) ## on affiche pour valider que ça diverge pas\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiCrUvECoTsx"
      },
      "source": [
        "Maintenant, on calcule la performance obtenue \n",
        "à travers la matrice de confusion\n",
        "Mij c'est le nombre de fois qu'une image de la classe i a été classé comme j"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUl-2z9FfRUG"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = np.zeros((10,10),dtype=int)\n",
        "\n",
        "monreseau.eval()\n",
        "with torch.no_grad():  ### ici pas besoin de calculer les gradients\n",
        "    for inputs, targets in testloader:\n",
        "        inputs = inputs.cuda()\n",
        "        outputs = monreseau(inputs)\n",
        "        _,pred = outputs.max(1)\n",
        "        cm += confusion_matrix(pred.cpu().numpy(),targets.cpu().numpy(),list(range(10)))\n",
        "\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVwdq_nMqCR9"
      },
      "source": [
        "Q1 (facile) : calculer le taux de bonne classification (donc la diagonale sur le total)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XlQ7IltqA-o"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJRTEjvGqOTr"
      },
      "source": [
        "### CNN\n",
        "\n",
        "Q2 (dur) : maintenant il faut changer le réseau pour mettre des convolutions et donc traiter la spécificité des images plutôt que de considérer ça comme un vecteur.\n",
        "\n",
        "Dupliquer le code de \"MonReseau\" et implémenter lenet au lieu d'un simple mlp\n",
        "\n",
        "regarder la doc : https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "\n",
        "et regarder sur internet pour lenet vous aurez plein d'info !!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0UVDKw2opzd"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ83_W9Mr7Y4"
      },
      "source": [
        "vous pouvez réutiliser quasiment tel quel la boucle \"d'apprentissage\" -- elle ne dépend PAS du réseau (les paramètres devrait peut être changer mais dans les grosses lignes c'est la même boucle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC2xtwaYsYxV"
      },
      "source": [
        "# CNN VS MLP\n",
        "\n",
        "Maintenant on va s'intéresser à la différence entre un mlp et un CNN\n",
        "\n",
        "Q3 (moyenne) : Coder une fonction qui prends en argument une permutation et une image et qui permute ses pixels.\n",
        "\n",
        "Ensuite tirer une permutation \"fixe\" (ce sera la même pour toutes les images train et test).\n",
        "\n",
        "Q4 (facile) :\n",
        "Regarder les images avant et après permutation -- pourriez vous (vous même) classer les images APRES permutation ??\n",
        "\n",
        "Q5 (facile) :\n",
        "Qu'est ce que ça change pour le MLP ??\n",
        "-> relancer l'apprentissage pour valider que ça ne change rien !\n",
        "\n",
        "Q6 (facile) : relancer le lenet -> là ça va changer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ds_JZ4aupBC"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laPww2Bnurqy"
      },
      "source": [
        "Q7 (moyenne) : faites une fonction qui ajoute du bruit (pour chaque pixel, mettez le à 0 ou à 1 avec une petite probabilité - le bruit est différent pour chaque image train et test)\n",
        "\n",
        "Q8 (facile) : Regarder les images avant et après permutation -- pourriez vous (vous même) classer les images APRES permutation ??\n",
        "\n",
        "Q9 (facile) : Tester le MLP et le CNN -> cette fois c'est le CNN qui devrait être invariant (le bruit est filtré par la convolution) alors que le MLP devrait être géné par le bruit !\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTA3zrQyxphh"
      },
      "source": [
        "print(\"TODO\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYYZMfsixq7g"
      },
      "source": [
        "## conclusion\n",
        "\n",
        "**-> se souvenir que si on prend TOUS les problèmes, tous les algos de classification sont tous aussi mauvais**\n",
        "\n",
        "**-> ce qui compte c'est qu'ils soient adaptés aux données qu'on peut réellement rencontrer**\n",
        "\n",
        "**En comparant les images avec permutation des pixels vs avec un bruit... Vous pouvez comprendre pourquoi le CNN est plus adapté à l'image que le MLP !**"
      ]
    }
  ]
}
