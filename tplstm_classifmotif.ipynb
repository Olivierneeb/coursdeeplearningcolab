{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tplstm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/tplstm_classifmotif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sX-k16KRvZiY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TP LSTM\n",
        "\n",
        "la liste des paquets nécessaires au programme\n"
      ]
    },
    {
      "metadata": {
        "id": "Lbev5unYvOVG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.autograd\n",
        "import torch.autograd.variable\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z0pCycDRvszu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "définition d'un générateur aléatoire de signaux :  \n",
        "* classe 0 -> rampe décroissante\n",
        "* classe 1 -> constante\n",
        "* classe 2 -> rampe croissante\n",
        "\n",
        "auquel on ajoute un bruit uniforme de grande intensité\n",
        "\n",
        "**l'objectif est d'être capable de prédire en chaque point s'il fait parti de la classe 0, 1 ou 2 (sachant qu'il y a des ambiguités à cause du bruit)**"
      ]
    },
    {
      "metadata": {
        "id": "xoNyIVQP0ONI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "N = 1\n",
        "T = 400\n",
        "def generateSample():\n",
        "    #generating gt and corresponding\n",
        "    y = np.zeros((T,N),dtype=int)\n",
        "    signal = np.zeros((T,N,1),dtype=int)\n",
        "    for n in range(N):\n",
        "        t=1\n",
        "        while t<T:\n",
        "            Dt = random.randint(10,40)\n",
        "            classe = random.randint(0,2)\n",
        "            while y[t-1][n]==classe and classe!=1:\n",
        "                classe = random.randint(0,2)    \n",
        "            for dt in range(Dt):\n",
        "                if t+dt<T:\n",
        "                    y[t+dt][n] = classe\n",
        "                    signal[t+dt][n][0] = (dt+1)*(classe-1)\n",
        "            t+=Dt\n",
        "    \n",
        "    #generating pure noise          \n",
        "    x = np.random.randint(-6,7,size=(T,N,1))\n",
        "\n",
        "    #adding the signal\n",
        "    x += signal\n",
        "    x = np.maximum(x,np.ones((T,N,1),dtype=int)*(-20))\n",
        "    x = np.minimum(x,np.ones((T,N,1),dtype=int)*19)\n",
        "    x += 20\n",
        "    \n",
        "    return x,y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pIdprpjM1rxX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "fonction de visualisation des signaux - de la classe et de la prédiction \n",
        "* vert pour la classe 0\n",
        "* bleu pour la classe 1\n",
        "* rose pour la classe 2"
      ]
    },
    {
      "metadata": {
        "id": "mdPJdl-615FO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualizecurve(x,y,z):\n",
        "    grid = np.ones((40*N,T,3),dtype=int)*255\n",
        "\n",
        "    for n in range(N):\n",
        "        for t in range(T):\n",
        "            if y[t][n]==0:\n",
        "                grid[40*n:40*n+20,t,:] = np.asarray([207,236,207])\n",
        "            if y[t][n]==1:\n",
        "                grid[40*n:40*n+20,t,:] = np.asarray([204,236,239])\n",
        "            if y[t][n]==2:\n",
        "                grid[40*n:40*n+20,t,:] = np.asarray([221,212,232])\n",
        "                \n",
        "            if z[t][n]==0:\n",
        "                grid[40*n+20:40*n+40,t,:] = np.asarray([207,236,207])\n",
        "            if z[t][n]==1:\n",
        "                grid[40*n+20:40*n+40,t,:] = np.asarray([204,236,239])\n",
        "            if z[t][n]==2:\n",
        "                grid[40*n+20:40*n+40,t,:] = np.asarray([221,212,232])\n",
        "            \n",
        "            grid[40*n+x[t][n]][t] = np.zeros(3,dtype=int)\n",
        "            \n",
        "    return np.uint8(grid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i4TOh4Lb2r9e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "classification de motifs"
      ]
    },
    {
      "metadata": {
        "id": "6T8uzric25Kj",
        "colab_type": "code",
        "outputId": "7c198770-bbec-4ef4-a891-9efc4d9c609c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.output1 = nn.Linear(5, 3, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        T,N,_ = x.shape\n",
        "        \n",
        "        #case N=1 remove N axis\n",
        "        x = x[:,0,0]\n",
        "        #now shape is (T)\n",
        "        \n",
        "        alloutput = []\n",
        "        for t in range(T-5):\n",
        "            vx = torch.autograd.Variable(torch.Tensor(np.expand_dims(x[t:t+5],axis=0)).float()) #linear expect Nx5 input\n",
        "\n",
        "            output = self.output1(vx)\n",
        "            \n",
        "            for i in range(5):\n",
        "                alloutput.append(output)\n",
        "            \n",
        "        return alloutput\n",
        "\n",
        "    def forwardnp(self,x):\n",
        "        T,N,_ = x.shape\n",
        "        \n",
        "        alloutput = self.forward(x)\n",
        "        \n",
        "        npprob = np.zeros((T,N,3),dtype=float)\n",
        "        for t in range(T): \n",
        "            npprob[t] = alloutput[t].cpu().data.numpy()\n",
        "        \n",
        "        pred = np.argmax(npprob,axis=2)\n",
        "        return pred,npprob\n",
        "\n",
        "model = Net()\n",
        "model.train()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (output1): Linear(in_features=5, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "Tb4zLxtm3Kp1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "l'apprentissage et les paramètres associés"
      ]
    },
    {
      "metadata": {
        "id": "H-vzcjZj3P_w",
        "colab_type": "code",
        "outputId": "186ddd2c-f367-4a3e-eb6e-b0c1ff98544c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "cell_type": "code",
      "source": [
        "lr = 0.00001\n",
        "momentum = 0.5\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "losslayer = nn.CrossEntropyLoss()\n",
        "\n",
        "from IPython.display import clear_output # command to clear the figures\n",
        "from time import sleep\n",
        "\n",
        "allprints = []\n",
        "nbepoch = 200\n",
        "for epoch in range(nbepoch):\n",
        "    x,y=generateSample()\n",
        "    \n",
        "    alloutput = model(x)\n",
        "\n",
        "    npprob = np.zeros((T,N,3),dtype=float)\n",
        "    for t in range(T): \n",
        "        npprob[t] = alloutput[t].cpu().data.numpy()\n",
        "    z = np.argmax(npprob,axis=2)\n",
        "\n",
        "    allloss = []\n",
        "    for t in range(T):\n",
        "        targett = torch.autograd.Variable(torch.from_numpy(y[t]).long())\n",
        "        losst = losslayer(alloutput[t], targett)\n",
        "        allloss.append(losst)\n",
        "\n",
        "    loss = sum(allloss)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch%8==0:\n",
        "        #show how it learn\n",
        "        nberror = (np.transpose(np.nonzero(y-z))).shape[0]\n",
        "        allprints.append((\"error=\",nberror,\"\\toptimisation loss=\", loss.cpu().data.numpy()))\n",
        "        visu = visualizecurve(x[:,:,0],y,z)\n",
        "        clear_output()\n",
        "        plt.imshow(visu)\n",
        "        plt.show()\n",
        "        for a,b,c,d in allprints:\n",
        "            print(a,b,c,d)\n",
        "        sleep(1)\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABECAYAAACPp/75AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntBxz9IZhGC3HHL1hGEbL+T8x83DwIjPA+gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "error= 234 \toptimisation loss= 953.52606\n",
            "error= 278 \toptimisation loss= 858.8984\n",
            "error= 281 \toptimisation loss= 1280.2716\n",
            "error= 283 \toptimisation loss= 1189.0123\n",
            "error= 223 \toptimisation loss= 680.4932\n",
            "error= 235 \toptimisation loss= 1431.0784\n",
            "error= 249 \toptimisation loss= 495.8606\n",
            "error= 302 \toptimisation loss= 2456.4578\n",
            "error= 281 \toptimisation loss= 1666.6292\n",
            "error= 242 \toptimisation loss= 1800.3988\n",
            "error= 273 \toptimisation loss= 653.83795\n",
            "error= 263 \toptimisation loss= 2658.6443\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f34904fb6f7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallprints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}