{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNX5W4L+WuHOJ7tV3qW5c25",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWdcxZdBXNp7",
        "colab_type": "text"
      },
      "source": [
        "#Formation deep learning\n",
        "\n",
        "L'objet de ce TP est de présenter brievement les outils de deep learning Pytorch. Il comporte 3 parties\n",
        "\n",
        "1.   Les briques de bases\n",
        "2.   Le traitement d'ECG par convolution\n",
        "3.   Les réseaux récurrents\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVtpJwPzbtSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.autograd\n",
        "import torch.autograd.variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWiZxWIaZvjd",
        "colab_type": "text"
      },
      "source": [
        "##Les briques de bases\n",
        "\n",
        "La brique de base de pytorch est l'objet Variable : il stocke en interne les opérations effectués sur un tenseur, de sorte à pouvoir calculer **automatiquement** le gradient d'une valeur par rapport aux autres.\n",
        "Considérons le problème de moindre carré où on veut minimiser f(beta) = beta * beta + (Y-X * beta)*(Y-X * beta) : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHyz0wNpXNE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y,X,beta = torch.rand(11),torch.rand((11,3)),torch.autograd.Variable(torch.rand(3),requires_grad=True)\n",
        "loss = torch.sum((Y-torch.mv(X,beta))*(Y-torch.mv(X,beta)))+torch.sum(beta*beta)\n",
        "print(X,Y,beta)\n",
        "print(\"initial loss=\",loss)\n",
        "loss.backward()\n",
        "print(beta.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvIVYOkTeDj7",
        "colab_type": "text"
      },
      "source": [
        "Ci dessus le gradient est automatiquement calculé, permettant par exemple de faire une descente de gradient à la main simplement. Cela dit, des optimiseurs (typiquement la descente de gradient) sont déjà précodés : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoTpV9ZkeWFZ",
        "colab_type": "code",
        "outputId": "3b8dce65-7b92-48e0-bf98-f3450bfa2c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "optimizer = optim.SGD([beta], lr=0.01, momentum=0.5)\n",
        "for i in range(10):\n",
        "  loss = torch.sum((Y-torch.mv(X,beta))*(Y-torch.mv(X,beta)))+torch.sum(beta*beta)\n",
        "  print(loss)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print(\"final loss=\", torch.sum((Y-torch.mv(X,beta))*(Y-torch.mv(X,beta)))+torch.sum(beta*beta))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(6.3581, grad_fn=<AddBackward0>)\n",
            "tensor(5.0682, grad_fn=<AddBackward0>)\n",
            "tensor(3.7385, grad_fn=<AddBackward0>)\n",
            "tensor(2.8703, grad_fn=<AddBackward0>)\n",
            "tensor(2.4405, grad_fn=<AddBackward0>)\n",
            "tensor(2.2658, grad_fn=<AddBackward0>)\n",
            "tensor(2.1951, grad_fn=<AddBackward0>)\n",
            "tensor(2.1517, grad_fn=<AddBackward0>)\n",
            "tensor(2.1110, grad_fn=<AddBackward0>)\n",
            "tensor(2.0709, grad_fn=<AddBackward0>)\n",
            "final loss= tensor(2.0343, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KgDj0I6fio1",
        "colab_type": "text"
      },
      "source": [
        "Faire une descente de gradient sur ce problème simple est donc trivial... \n",
        "\n",
        "**Mais on n'est pas là pour faire de la régression moindre carré...**\n",
        "\n",
        "##Traitement de données ECG\n",
        "\n",
        "On considère maintenant des données (réel - voir https://physionet.org/physiobank/database/qtdb/) d'ECG annotés - à chaque instant, on a 2 valeurs brutes (ne me demander pas à quoi ça correspond, je n'en ai aucune idée) **et** on sait si on est dans l'état P, T ou U (ne me demander pas à quoi ça correspond, je n'en ai aucune idée). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwlwHBha3I2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"https://github.com/achanhon/coursdeeplearningcolab/blob/master/ECG_data/alldata.npz?raw=true\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFLTi2BThM4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "allecgdata = np.load(\"alldata.npz?raw=true\")\n",
        "allecgdata = allecgdata[\"arr_0\"]\n",
        "print(allecgdata,allecgdata.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYdb1Bv5hb8k",
        "colab_type": "text"
      },
      "source": [
        "Nous avons donc 105 enregistrements (1 par patients) de 8192 instants (je ne connais pas la fréquence). On va commencer par se familiariser avec les données : **70% du temps de développement c'est de s'adapter au données**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4XyWyYSh4yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython.display\n",
        "import PIL.Image\n",
        "\n",
        "def visualizecurve(x,y,z):\n",
        "    grid = np.ones((200,1000,3),dtype=int)*255\n",
        "    x = x[0:1000]\n",
        "    x = x-min(x)\n",
        "    x = x*400/max(x)\n",
        "    \n",
        "    x = np.minimum(x,np.ones(1000)*180)\n",
        "    x = x.astype(int)\n",
        "    y = y.astype(int)\n",
        "    \n",
        "    if z is not None:\n",
        "        for t in range(1000):\n",
        "            grid[x[t]][t][:] = 0\n",
        "            grid[0:20,t,y[t]] = 0            \n",
        "            grid[180:200,t,z[t]] = 0\n",
        "    else:\n",
        "        for t in range(1000):\n",
        "            grid[x[t]][t][:] = 0\n",
        "            grid[0:20,t,y[t]] = 0            \n",
        "        \n",
        "    return np.uint8(grid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2v5W4aiv03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randompatient = np.random.randint(105, size=1)[0]\n",
        "IPython.display.display(PIL.Image.fromarray(visualizecurve(allecgdata[randompatient][0],allecgdata[randompatient][2],None)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG_0hNG0jqgK",
        "colab_type": "text"
      },
      "source": [
        "On voit donc l'ECG et les 3 labels P,T,U représentés par 3 couleurs au dessus.\n",
        "*Bon j'admets que c'est pas très beau comme affichage mais...*\n",
        "\n",
        "**Notre objectif est d'apprendre à un réseau à prédire ce label (à chaque instant) à partir de l'ECG. Lors de l'apprentissage le réseau utilise l'ECG et le label pour mettre à jours ses poids. En test, on n'utilise que l'ECG et on prédit un label (puis on compare avec le label réel pour voir si ça marche).**\n",
        "\n",
        "Commençons par couper train/test aléatoirement :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQdcGYfkgI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X,Y = [],[]    \n",
        "for i in range(allecgdata.shape[0]):\n",
        "    X.append(allecgdata[i][0:2])\n",
        "    Y.append(allecgdata[i][2].astype(int))\n",
        "\n",
        "X,Y = shuffle(X,Y)\n",
        "\n",
        "Xtest,Ytest = X[0:15],Y[0:15]\n",
        "X,Y = X[15:],Y[15:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAan3YmgmYuM",
        "colab_type": "text"
      },
      "source": [
        "Et introduisons notre fonction d'évaluation : on prend X, Y et un model et on compte le nombre de fois qu'on a prédit la bonne réponse - **accuracy** en anglais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vfAJbqWmdAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_model(X,Y,model):\n",
        "    cm = np.zeros((3,3),dtype=int)\n",
        "    Z = model(torch.Tensor(np.stack(X)))\n",
        "    Z = Z.cpu().data.numpy()\n",
        "    Z = np.argmax(Z,axis=1)\n",
        "    for i in range(len(Y)):\n",
        "        cm += confusion_matrix(Y[i], Z[i],list(range(3)))\n",
        "    return (cm[0][0]+cm[1][1]+cm[2][2])/(np.sum(cm)+1),cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIBUGaImjqXj",
        "colab_type": "text"
      },
      "source": [
        "Maintenant, définissons un réseau qui apprend à segmenter. Pour commencer on va mettre juste 2 couches (ça va pas marcher mais c'est pour introduire le code)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rNSbJKklXh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PetitNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PetitNet, self).__init__()\n",
        "        self.bnm1 = nn.BatchNorm1d(2, momentum=0.1)\n",
        "        self.fc0 = nn.Conv1d(2, 32, kernel_size=11, padding=5)\n",
        "        self.fc1 = nn.Conv1d(32, 3, kernel_size=11, padding=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bnm1(x)\n",
        "        \n",
        "        x = F.leaky_relu(self.fc0(x))\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=1, padding=2)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = PetitNet()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "losslayer = nn.CrossEntropyLoss()\n",
        "batchsize = 50\n",
        "\n",
        "import collections\n",
        "memoryofloss = collections.deque(maxlen=200)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcOrsIhSmMhQ",
        "colab_type": "text"
      },
      "source": [
        "Lancer le code d'apprentissage ci dessous - comme il devrait prendre 5 mins, vous pouvez ensuite chercher à comprendre ce qu'il fait"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nza1RrjZmJ4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for iteration in range(500):\n",
        "    model.train()\n",
        "    \n",
        "    X,Y = shuffle(X,Y)\n",
        "    Ybatch = np.stack(Y[0:batchsize])\n",
        "    Z = model(torch.Tensor(np.stack(X[0:batchsize])))\n",
        "        \n",
        "    # move from BATCH x NB CLASSES x 8192 to 409600 x NB CLASSES\n",
        "    Z = torch.transpose(Z,1,2)\n",
        "    Z = Z.contiguous().view(409600,3)\n",
        "    Ybatch = Ybatch.flatten()\n",
        "    Ybatch = torch.from_numpy(Ybatch).long()\n",
        "    \n",
        "    loss = losslayer(Z,Ybatch)\n",
        "    \n",
        "    memoryofloss.append(loss.cpu().data.numpy())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if iteration%100==99:\n",
        "        print(sum(memoryofloss)/len(memoryofloss))\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            print(eval_model(Xtest,Ytest,model))\n",
        "            print(eval_model(X,Y,model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pYMh-6PptYn",
        "colab_type": "text"
      },
      "source": [
        "Le code correspond juste à faire une boucle, dans laquelle on prend un bloc de données (batch), on le fait passer dans le réseau (ça produit Z). Après, il y a un peu de truc bizarre pour remettre les variables dans le bon format, mais ce qui compte c'est qu'on calcule une loss entre Z les prédictions et Y ce qu'on veut.\n",
        "Puis, on fait une descente de gradient.\n",
        "\n",
        "Mais ici, ça ne marche pas : le réseau n'est pas assez expressif - il n'est ni bon sur la base d'apprentissage - ni sur celle de test (s'il était bon sur celle d'apprentissage mais pas de test, il n'y aurait pas beaucoup d'espoir - mais là si).\n",
        "Rajouter des couches (convolution et pooling) pour que ça marche mieux.\n",
        "\n",
        "Vous pouvez aussi aller jouer avec https://playground.tensorflow.org qui propose la même chose en plus jolie sur des données vectorielles (des points 2D, ici on a un signal temporel)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWLgQzRys1-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"A VOUS DE JOUER\")\n",
        "print(\"Vous pouvez utiliser les fonctions de visualisation pour voir ce que ça donne (quand ça commence à marcher)\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N1mN-sosyHw",
        "colab_type": "text"
      },
      "source": [
        "##Les réseaux récurrents\n",
        "\n",
        "Passons maintenant aux réseaux récurrents\n",
        "\n",
        "#TODO"
      ]
    }
  ]
}