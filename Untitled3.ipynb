{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNk40YHl8thILiiDyHweTN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/coursdeeplearningcolab/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWdcxZdBXNp7",
        "colab_type": "text"
      },
      "source": [
        "#Formation deep learning\n",
        "\n",
        "L'objet de ce TP est de présenter brievement les outils de deep learning Pytorch. Il comporte 3 parties\n",
        "\n",
        "1.   Les briques de bases\n",
        "2.   Le traitement d'ECG par convolution\n",
        "3.   Les réseaux récurrents\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVtpJwPzbtSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.autograd\n",
        "import torch.autograd.variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWiZxWIaZvjd",
        "colab_type": "text"
      },
      "source": [
        "##Les briques de bases\n",
        "\n",
        "La brique de base de pytorch est l'objet Variable : il stocke en interne les opérations effectués sur un tenseur, de sorte à pouvoir calculer **automatiquement** le gradient d'une valeur par rapport aux autres.\n",
        "Considérons le problème de moindre carré où on veut minimiser f(beta) = beta * beta + (Y-X * beta)*(Y-X * beta) : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHyz0wNpXNE_",
        "colab_type": "code",
        "outputId": "4922658d-9ee6-4b66-b26f-4906a3bbea83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "Y,X,beta = torch.rand(11),torch.rand((11,3)),torch.autograd.Variable(torch.rand(3),requires_grad=True)\n",
        "loss = torch.sum((Y-torch.mv(X,beta))*(Y-torch.mv(X,beta)))+torch.sum(beta*beta)\n",
        "print(X,Y,beta)\n",
        "print(\"initial loss=\",loss)\n",
        "loss.backward()\n",
        "print(beta.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2496, 0.6576, 0.7934],\n",
            "        [0.7771, 0.6098, 0.3607],\n",
            "        [0.7937, 0.2936, 0.6671],\n",
            "        [0.5276, 0.4701, 0.4754],\n",
            "        [0.6158, 0.6170, 0.9910],\n",
            "        [0.3099, 0.0112, 0.4645],\n",
            "        [0.7243, 0.3367, 0.1595],\n",
            "        [0.1147, 0.6365, 0.1373],\n",
            "        [0.5810, 0.6759, 0.0774],\n",
            "        [0.4338, 0.3055, 0.7214],\n",
            "        [0.0661, 0.6882, 0.2986]]) tensor([0.0266, 0.8459, 0.9874, 0.7657, 0.1053, 0.4441, 0.0086, 0.7915, 0.4674,\n",
            "        0.8436, 0.3709]) tensor([0.2177, 0.9207, 0.8636], requires_grad=True)\n",
            "initial loss= tensor(6.3581, grad_fn=<AddBackward0>)\n",
            "tensor([4.9224, 7.4322, 7.8678])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvIVYOkTeDj7",
        "colab_type": "text"
      },
      "source": [
        "Ci dessus le gradient est automatiquement calculé, permettant par exemple de faire une descente de gradient à la main simplement. Cela dit, des optimiseurs (typiquement la descente de gradient) sont déjà précodés : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoTpV9ZkeWFZ",
        "colab_type": "code",
        "outputId": "3b8dce65-7b92-48e0-bf98-f3450bfa2c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "optimizer = optim.SGD([beta], lr=0.01, momentum=0.5)\n",
        "for i in range(10):\n",
        "  loss = torch.sum((Y-torch.mv(X,beta))*(Y-torch.mv(X,beta)))+torch.sum(beta*beta)\n",
        "  print(loss)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print(\"final loss=\", torch.sum((Y-torch.mv(X,beta))*(Y-torch.mv(X,beta)))+torch.sum(beta*beta))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(6.3581, grad_fn=<AddBackward0>)\n",
            "tensor(5.0682, grad_fn=<AddBackward0>)\n",
            "tensor(3.7385, grad_fn=<AddBackward0>)\n",
            "tensor(2.8703, grad_fn=<AddBackward0>)\n",
            "tensor(2.4405, grad_fn=<AddBackward0>)\n",
            "tensor(2.2658, grad_fn=<AddBackward0>)\n",
            "tensor(2.1951, grad_fn=<AddBackward0>)\n",
            "tensor(2.1517, grad_fn=<AddBackward0>)\n",
            "tensor(2.1110, grad_fn=<AddBackward0>)\n",
            "tensor(2.0709, grad_fn=<AddBackward0>)\n",
            "final loss= tensor(2.0343, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KgDj0I6fio1",
        "colab_type": "text"
      },
      "source": [
        "Faire une descente de gradient sur ce problème simple est donc trivial... \n",
        "\n",
        "**Mais on n'est pas là pour faire de la régression moindre carré...**\n",
        "\n",
        "##Traitement de données ECG\n",
        "\n",
        "On considère maintenant des données (réel - voir https://physionet.org/physiobank/database/qtdb/) d'ECG annotés - à chaque instant, on a 2 valeurs brutes (ne me demander pas à quoi ça correspond, je n'en ai aucune idée) **et** on sait si on est dans l'état P, T ou U (ne me demander pas à quoi ça correspond, je n'en ai aucune idée). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwlwHBha3I2y",
        "colab_type": "code",
        "outputId": "f2c35c0d-b48f-4a1d-ba26-319c46629381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!wget \"https://github.com/achanhon/coursdeeplearningcolab/blob/master/ECG_data/alldata.npz?raw=true\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-24 12:27:31--  https://github.com/achanhon/coursdeeplearningcolab/blob/master/ECG_data/alldata.npz?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/achanhon/coursdeeplearningcolab/raw/master/ECG_data/alldata.npz [following]\n",
            "--2020-01-24 12:27:32--  https://github.com/achanhon/coursdeeplearningcolab/raw/master/ECG_data/alldata.npz\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/achanhon/coursdeeplearningcolab/master/ECG_data/alldata.npz [following]\n",
            "--2020-01-24 12:27:32--  https://raw.githubusercontent.com/achanhon/coursdeeplearningcolab/master/ECG_data/alldata.npz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2009378 (1.9M) [application/octet-stream]\n",
            "Saving to: ‘alldata.npz?raw=true’\n",
            "\n",
            "alldata.npz?raw=tru 100%[===================>]   1.92M  9.36MB/s    in 0.2s    \n",
            "\n",
            "2020-01-24 12:27:34 (9.36 MB/s) - ‘alldata.npz?raw=true’ saved [2009378/2009378]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFLTi2BThM4b",
        "colab_type": "code",
        "outputId": "bbef3405-ed63-4696-a97d-5a1a76c08c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "import numpy as np\n",
        "allecgdata = np.load(\"alldata.npz?raw=true\")\n",
        "allecgdata = allecgdata[\"arr_0\"]\n",
        "print(allecgdata,allecgdata.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 4.75   4.77   4.78  ...  4.77   4.765  4.765]\n",
            "  [ 4.865  4.86   4.86  ...  4.915  4.915  4.91 ]\n",
            "  [ 0.     0.     0.    ...  1.     1.     1.   ]]\n",
            "\n",
            " [[ 4.75   4.725  4.725 ...  4.995  5.005  4.995]\n",
            "  [ 5.     5.01   5.025 ...  5.265  5.255  5.225]\n",
            "  [ 1.     1.     1.    ...  2.     2.     2.   ]]\n",
            "\n",
            " [[ 4.93   4.93   4.93  ...  6.58   6.975  7.025]\n",
            "  [ 5.115  5.12   5.105 ...  5.98   6.345  6.52 ]\n",
            "  [ 0.     0.     0.    ...  1.     1.     1.   ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-6.2   -6.2   -6.2   ... -6.34  -6.34  -6.34 ]\n",
            "  [-1.67  -1.675 -1.665 ... -1.67  -1.705 -1.73 ]\n",
            "  [ 0.     0.     0.    ...  1.     1.     1.   ]]\n",
            "\n",
            " [[-3.55  -3.545 -3.55  ... -3.635 -3.635 -3.635]\n",
            "  [-0.1   -0.1   -0.105 ... -0.11  -0.105 -0.115]\n",
            "  [ 0.     0.     0.    ...  2.     2.     2.   ]]\n",
            "\n",
            " [[-3.64  -3.64  -3.64  ... -3.715 -3.72  -3.755]\n",
            "  [-2.24  -2.23  -2.25  ... -2.115 -2.085 -2.045]\n",
            "  [ 0.     0.     0.    ...  1.     1.     1.   ]]] (105, 3, 8192)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYdb1Bv5hb8k",
        "colab_type": "text"
      },
      "source": [
        "Nous avons donc 105 enregistrements (1 par patients) de 8192 instants (je ne connais pas la fréquence). On va commencer par se familiariser avec les données : **70% du temps de développement c'est de s'adapter au données**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4XyWyYSh4yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython.display\n",
        "import PIL.Image\n",
        "\n",
        "def visualizecurve(x,y,z):\n",
        "    grid = np.ones((200,1000,3),dtype=int)*255\n",
        "    x = x[0:1000]\n",
        "    x = x-min(x)\n",
        "    x = x*400/max(x)\n",
        "    \n",
        "    x = np.minimum(x,np.ones(1000)*180)\n",
        "    x = x.astype(int)\n",
        "    y = y.astype(int)\n",
        "    \n",
        "    if z is not None:\n",
        "        for t in range(1000):\n",
        "            grid[x[t]][t][:] = 0\n",
        "            grid[0:20,t,y[t]] = 0            \n",
        "            grid[180:200,t,z[t]] = 0\n",
        "    else:\n",
        "        for t in range(1000):\n",
        "            grid[x[t]][t][:] = 0\n",
        "            grid[0:20,t,y[t]] = 0            \n",
        "        \n",
        "    return np.uint8(grid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2v5W4aiv03",
        "colab_type": "code",
        "outputId": "83671387-0acf-435b-c7ac-caf6e11f4a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "randompatient = np.random.randint(105, size=1)[0]\n",
        "IPython.display.display(PIL.Image.fromarray(visualizecurve(allecgdata[randompatient][0],allecgdata[randompatient][2],None)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAADICAIAAAD0hVwYAAAPx0lEQVR4nO3d266juBIAUBid///l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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=1000x200 at 0x7FD7ECDC5630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG_0hNG0jqgK",
        "colab_type": "text"
      },
      "source": [
        "On voit donc l'ECG et les 3 labels P,T,U représentés par 3 couleurs au dessus.\n",
        "*Bon j'admets que c'est pas très beau comme affichage mais...*\n",
        "\n",
        "**Notre objectif est d'apprendre à un réseau à prédire ce label (à chaque instant) à partir de l'ECG. Lors de l'apprentissage le réseau utilise l'ECG et le label pour mettre à jours ses poids. En test, on n'utilise que l'ECG et on prédit un label (puis on compare avec le label réel pour voir si ça marche).**\n",
        "\n",
        "Commençons par couper train/test aléatoirement :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQdcGYfkgI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X,Y = [],[]    \n",
        "for i in range(allecgdata.shape[0]):\n",
        "    X.append(allecgdata[i][0:2])\n",
        "    Y.append(allecgdata[i][2].astype(int))\n",
        "\n",
        "X,Y = shuffle(X,Y)\n",
        "\n",
        "Xtest,Ytest = X[0:15],Y[0:15]\n",
        "X,Y = X[15:],Y[15:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAan3YmgmYuM",
        "colab_type": "text"
      },
      "source": [
        "Et introduisons notre fonction d'évaluation : on prend X, Y et un model et on compte le nombre de fois qu'on a prédit la bonne réponse - **accuracy** en anglais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vfAJbqWmdAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_model(X,Y,model):\n",
        "    cm = np.zeros((3,3),dtype=int)\n",
        "    Z = model(torch.Tensor(np.stack(X)))\n",
        "    Z = Z.cpu().data.numpy()\n",
        "    Z = np.argmax(Z,axis=1)\n",
        "    for i in range(len(Y)):\n",
        "        cm += confusion_matrix(Y[i], Z[i],list(range(3)))\n",
        "    return (cm[0][0]+cm[1][1]+cm[2][2])/(np.sum(cm)+1),cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIBUGaImjqXj",
        "colab_type": "text"
      },
      "source": [
        "Maintenant, définissons un réseau qui apprend à segmenter. Pour commencer on va mettre juste 2 couches (ça va pas marcher mais c'est pour introduire le code)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rNSbJKklXh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PetitNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PetitNet, self).__init__()\n",
        "        self.bnm1 = nn.BatchNorm1d(2, momentum=0.1)\n",
        "        self.fc0 = nn.Conv1d(2, 32, kernel_size=11, padding=5)\n",
        "        self.fc1 = nn.Conv1d(32, 3, kernel_size=11, padding=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bnm1(x)\n",
        "        \n",
        "        x = F.leaky_relu(self.fc0(x))\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=1, padding=2)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = PetitNet()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "losslayer = nn.CrossEntropyLoss()\n",
        "batchsize = 50\n",
        "\n",
        "import collections\n",
        "memoryofloss = collections.deque(maxlen=200)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcOrsIhSmMhQ",
        "colab_type": "text"
      },
      "source": [
        "Lancer le code d'apprentissage ci dessous - comme il devrait prendre 5 mins, vous pouvez ensuite chercher à comprendre ce qu'il fait"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nza1RrjZmJ4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for iteration in range(500):\n",
        "    model.train()\n",
        "    \n",
        "    X,Y = shuffle(X,Y)\n",
        "    Ybatch = np.stack(Y[0:batchsize])\n",
        "    Z = model(torch.Tensor(np.stack(X[0:batchsize])))\n",
        "        \n",
        "    # move from BATCH x NB CLASSES x 8192 to 409600 x NB CLASSES\n",
        "    Z = torch.transpose(Z,1,2)\n",
        "    Z = Z.contiguous().view(409600,3)\n",
        "    Ybatch = Ybatch.flatten()\n",
        "    Ybatch = torch.from_numpy(Ybatch).long()\n",
        "    \n",
        "    loss = losslayer(Z,Ybatch)\n",
        "    \n",
        "    memoryofloss.append(loss.cpu().data.numpy())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if iteration%100==99:\n",
        "        print(sum(memoryofloss)/len(memoryofloss))\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            print(eval_model(Xtest,Ytest,model))\n",
        "            print(eval_model(X,Y,model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pYMh-6PptYn",
        "colab_type": "text"
      },
      "source": [
        "Le code correspond juste à faire une boucle, dans laquelle on prend un bloc de données (batch), on le fait passer dans le réseau (ça produit Z). Après, il y a un peu de truc bizarre pour remettre les variables dans le bon format, mais ce qui compte c'est qu'on calcule une loss entre Z les prédictions et Y ce qu'on veut.\n",
        "Puis, on fait une descente de gradient.\n",
        "\n",
        "Mais ici, ça ne marche pas : le réseau n'est pas assez expressif - il n'est ni bon sur la base d'apprentissage - ni sur celle de test (s'il était bon sur celle d'apprentissage mais pas de test, il n'y aurait pas beaucoup d'espoir - mais là si).\n",
        "Rajouter des couches (convolution et pooling) pour que ça marche mieux.\n",
        "\n",
        "Vous pouvez aussi aller jouer avec https://playground.tensorflow.org qui propose la même chose en plus jolie sur des données vectorielles (des points 2D, ici on a un signal temporel)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWLgQzRys1-I",
        "colab_type": "code",
        "outputId": "0b7c1aae-457b-4e5b-deb4-45c84188a973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"A VOUS DE JOUER\")\n",
        "print(\"Vous pouvez utiliser les fonctions de visualisation pour voir ce que ça donne (quand ça commence à marcher)\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A VOUS DE JOUER\n",
            "Vous pouvez utiliser les fonctions de visualisation pour voir ce que ça donne (quand ça commence à marcher)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N1mN-sosyHw",
        "colab_type": "text"
      },
      "source": [
        "##Les réseaux récurrents\n",
        "\n",
        "Passons maintenant aux réseaux récurrents\n",
        "\n"
      ]
    }
  ]
}